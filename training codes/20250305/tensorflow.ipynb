{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best so far but old features\n",
    "Use stratified kfold\n",
    "This only use feature that we use in feature importance\n",
    "Not include ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:45:59.346470: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740156359.368419  810749 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740156359.374758  810749 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-21 16:45:59.400819: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "tf.keras.utils.set_random_seed(SEED)  # This sets all random seeds in keras\n",
    "tf.config.experimental.enable_op_determinism()  # For complete reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGNNLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.node_update = tf.keras.layers.Dense(units)\n",
    "        self.message = tf.keras.layers.Dense(units)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        node_features, edge_index, edge_features, node_mask, edge_mask = inputs\n",
    "        \n",
    "        # Basic message passing\n",
    "        edge_index = tf.cast(edge_index, tf.int32)\n",
    "        source_nodes = tf.gather(node_features, edge_index[..., 0], batch_dims=1)\n",
    "        \n",
    "        # Simple messages\n",
    "        messages = self.message(source_nodes)\n",
    "        messages = messages * tf.expand_dims(edge_mask, -1)\n",
    "        \n",
    "        # Aggregate messages (sum)\n",
    "        batch_size = tf.shape(node_features)[0]\n",
    "        num_nodes = tf.shape(node_features)[1]\n",
    "        \n",
    "        # Create batch indices for scatter\n",
    "        batch_range = tf.range(batch_size, dtype=tf.int32)\n",
    "        batch_range = tf.expand_dims(batch_range, -1)\n",
    "        batch_range = tf.tile(batch_range, [1, tf.shape(edge_index)[1]])\n",
    "        \n",
    "        scatter_indices = tf.stack([\n",
    "            tf.reshape(batch_range, [-1]),\n",
    "            tf.reshape(edge_index[..., 1], [-1])\n",
    "        ], axis=1)\n",
    "        \n",
    "        messages = tf.reshape(messages, [-1, self.units])\n",
    "        output_shape = tf.stack([batch_size, num_nodes, self.units])\n",
    "        aggregated = tf.zeros(output_shape)\n",
    "        aggregated = tf.tensor_scatter_nd_add(aggregated, scatter_indices, messages)\n",
    "        \n",
    "        # Update node features\n",
    "        updated = self.node_update(tf.concat([node_features, aggregated], axis=-1))\n",
    "        updated = updated * tf.expand_dims(node_mask, -1)\n",
    "        \n",
    "        return tf.nn.relu(updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.dense = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        node_features, edge_index, edge_features, node_mask, edge_mask = inputs\n",
    "        \n",
    "        edge_index = tf.cast(edge_index, tf.int32)\n",
    "        source_nodes = tf.gather(node_features, edge_index[..., 0], batch_dims=1)\n",
    "        target_nodes = tf.gather(node_features, edge_index[..., 1], batch_dims=1)\n",
    "        \n",
    "        # Normalize by degree (approximated by edge mask sum)\n",
    "        degree = tf.reduce_sum(edge_mask, axis=-1, keepdims=True)\n",
    "        degree = tf.maximum(degree, 1.0)  # Avoid division by zero\n",
    "        norm = tf.math.rsqrt(degree)\n",
    "        \n",
    "        # GCN propagation\n",
    "        messages = source_nodes * tf.expand_dims(norm, -1)\n",
    "        messages = messages * tf.expand_dims(edge_mask, -1)\n",
    "        \n",
    "        # Aggregate\n",
    "        batch_size = tf.shape(node_features)[0]\n",
    "        num_nodes = tf.shape(node_features)[1]\n",
    "        \n",
    "        batch_range = tf.range(batch_size, dtype=tf.int32)\n",
    "        batch_range = tf.expand_dims(batch_range, -1)\n",
    "        batch_range = tf.tile(batch_range, [1, tf.shape(edge_index)[1]])\n",
    "        \n",
    "        scatter_indices = tf.stack([\n",
    "            tf.reshape(batch_range, [-1]),\n",
    "            tf.reshape(edge_index[..., 1], [-1])\n",
    "        ], axis=1)\n",
    "        \n",
    "        messages = tf.reshape(messages, [-1, node_features.shape[-1]])\n",
    "        output_shape = tf.stack([batch_size, num_nodes, node_features.shape[-1]])\n",
    "        aggregated = tf.zeros(output_shape)\n",
    "        aggregated = tf.tensor_scatter_nd_add(aggregated, scatter_indices, messages)\n",
    "        \n",
    "        # Linear transformation\n",
    "        output = self.dense(aggregated)\n",
    "        output = output * tf.expand_dims(node_mask, -1)\n",
    "        \n",
    "        return tf.nn.relu(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = units // num_heads\n",
    "        \n",
    "        self.query = tf.keras.layers.Dense(units)\n",
    "        self.key = tf.keras.layers.Dense(units)\n",
    "        self.value = tf.keras.layers.Dense(units)\n",
    "        self.combine = tf.keras.layers.Dense(units)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        node_features, edge_index, edge_features, node_mask, edge_mask = inputs\n",
    "        \n",
    "        edge_index = tf.cast(edge_index, tf.int32)\n",
    "        batch_size = tf.shape(node_features)[0]\n",
    "        num_nodes = tf.shape(node_features)[1]\n",
    "        \n",
    "        # Multi-head attention\n",
    "        q = self.query(node_features)  # [batch, nodes, units]\n",
    "        k = self.key(node_features)    # [batch, nodes, units]\n",
    "        v = self.value(node_features)  # [batch, nodes, units]\n",
    "        \n",
    "        # Reshape for multiple heads\n",
    "        q = tf.reshape(q, [batch_size, num_nodes, self.num_heads, self.head_dim])\n",
    "        k = tf.reshape(k, [batch_size, num_nodes, self.num_heads, self.head_dim])\n",
    "        v = tf.reshape(v, [batch_size, num_nodes, self.num_heads, self.head_dim])\n",
    "        \n",
    "        # Get source and target nodes\n",
    "        source_nodes = tf.gather(k, edge_index[..., 0], batch_dims=1)  # [batch, edges, heads, head_dim]\n",
    "        target_nodes = tf.gather(q, edge_index[..., 1], batch_dims=1)  # [batch, edges, heads, head_dim]\n",
    "        \n",
    "        # Compute attention scores\n",
    "        scores = tf.reduce_sum(source_nodes * target_nodes, axis=-1)  # [batch, edges, heads]\n",
    "        scores = tf.nn.softmax(scores, axis=1)\n",
    "        scores = scores * tf.expand_dims(edge_mask, -1)\n",
    "        \n",
    "        # Apply attention to values\n",
    "        values = tf.gather(v, edge_index[..., 0], batch_dims=1)\n",
    "        messages = tf.expand_dims(scores, -1) * values\n",
    "        \n",
    "        # Aggregate messages\n",
    "        batch_range = tf.range(batch_size, dtype=tf.int32)\n",
    "        batch_range = tf.expand_dims(batch_range, -1)\n",
    "        batch_range = tf.tile(batch_range, [1, tf.shape(edge_index)[1]])\n",
    "        \n",
    "        scatter_indices = tf.stack([\n",
    "            tf.reshape(batch_range, [-1]),\n",
    "            tf.reshape(edge_index[..., 1], [-1])\n",
    "        ], axis=1)\n",
    "        \n",
    "        messages = tf.reshape(messages, [-1, self.num_heads * self.head_dim])\n",
    "        output_shape = tf.stack([batch_size, num_nodes, self.num_heads * self.head_dim])\n",
    "        aggregated = tf.zeros(output_shape)\n",
    "        aggregated = tf.tensor_scatter_nd_add(aggregated, scatter_indices, messages)\n",
    "        \n",
    "        # Combine heads\n",
    "        output = self.combine(aggregated)\n",
    "        output = output * tf.expand_dims(node_mask, -1)\n",
    "        \n",
    "        return tf.nn.relu(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edge_features(i, j, dist_map, sequence, ss_string, sasa_vals, K_POS=16):\n",
    "    \"\"\"\n",
    "    Create edge features with proper padding handling using sequence\n",
    "    Returns a fixed-size numpy array\n",
    "    \"\"\"\n",
    "    edge_features = np.zeros(18, dtype=np.float32)  # Pre-allocate fixed size array\n",
    "    distance = dist_map[i,j]\n",
    "    \n",
    "    # Check if either position is padded using sequence\n",
    "    is_i_padded = sequence[i] == '-'\n",
    "    is_j_padded = sequence[j] == '-'\n",
    "    \n",
    "    if is_i_padded or is_j_padded:\n",
    "        return edge_features  # Return zero array for padded positions\n",
    "    \n",
    "    feature_idx = 0\n",
    "    \n",
    "    # 1. Distance Features\n",
    "    # Distance bins (4 features)\n",
    "    if distance <= 4.0:\n",
    "        edge_features[0] = 1.0\n",
    "    elif distance <= 8.0:\n",
    "        edge_features[1] = 1.0\n",
    "    elif distance <= 12.0:\n",
    "        edge_features[2] = 1.0\n",
    "    else:\n",
    "        edge_features[3] = 1.0\n",
    "    feature_idx += 4\n",
    "    \n",
    "    # Continuous distance feature (1 feature)\n",
    "    edge_features[feature_idx] = 1/distance\n",
    "    feature_idx += 1\n",
    "    \n",
    "    # 2. Sequential Features (2 features)\n",
    "    seq_dist = abs(i - j)\n",
    "    edge_features[feature_idx] = float(seq_dist == 1)  # Is sequential\n",
    "    edge_features[feature_idx + 1] = seq_dist / 32.0  # Normalized distance\n",
    "    feature_idx += 2\n",
    "    \n",
    "    # 3. K-relative Features (2 features)\n",
    "    edge_features[feature_idx] = float(i == K_POS or j == K_POS)  # Is K-connected\n",
    "    edge_features[feature_idx + 1] = min(abs(i - K_POS), abs(j - K_POS)) / 16.0  # Min distance to K\n",
    "    feature_idx += 2\n",
    "    \n",
    "    # 4. Secondary Structure Interaction (6 features)\n",
    "    ss_pairs = ['HH', 'HE', 'HL', 'EE', 'EL', 'LL']\n",
    "    ss_pair = ''.join(sorted([ss_string[i], ss_string[j]]))\n",
    "    for idx, pair in enumerate(ss_pairs):\n",
    "        edge_features[feature_idx + idx] = float(ss_pair == pair)\n",
    "    feature_idx += 6\n",
    "    \n",
    "    # 5. SASA Interaction (2 features)\n",
    "    edge_features[feature_idx] = abs(sasa_vals[i] - sasa_vals[j])  # SASA difference\n",
    "    edge_features[feature_idx + 1] = (sasa_vals[i] + sasa_vals[j]) / 2  # SASA average\n",
    "    \n",
    "    return edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_feature_size():\n",
    "    \"\"\"Calculate the total size of node features\"\"\"\n",
    "    # Backbone angles (phi, psi, omega) - each has sin and cos\n",
    "    backbone_size = 3 * 2\n",
    "\n",
    "    # SASA - single value\n",
    "    sasa_size = 1\n",
    "\n",
    "    # SS one-hot encoding (H, E, L)\n",
    "    ss_size = 3\n",
    "\n",
    "    # plDDT score - single value\n",
    "    plddt_size = 1\n",
    "\n",
    "    # Chi angles (chi1-4) - each has sin and cos\n",
    "    chi_size = 4 * 2\n",
    "\n",
    "    # K-relative features\n",
    "    # - Distance to K (normalized)\n",
    "    # - Is K position\n",
    "    # - Is K amino acid\n",
    "    k_relative_size = 3\n",
    "\n",
    "    total_size = backbone_size + sasa_size + ss_size + plddt_size + chi_size + k_relative_size\n",
    "    return total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_gnn_data(df, threshold=8.0, max_nodes=33, max_edges=300):\n",
    "    \"\"\"\n",
    "    Prepare node and edge features using sequence for padding detection\n",
    "    \"\"\"\n",
    "    node_features_list = []\n",
    "    edge_indices_list = []\n",
    "    edge_features_list = []\n",
    "    node_masks_list = []\n",
    "    edge_masks_list = []\n",
    "    \n",
    "    K_POS = 16\n",
    "    \n",
    "    print(\"Processing samples for GNN...\")\n",
    "    for idx, row in df.iterrows():\n",
    "        sequence = row['sequence']\n",
    "        # Use sequence for padding detection\n",
    "        is_padded = [pos for pos, aa in enumerate(sequence) if aa == '-']\n",
    "        \n",
    "        # Pre-allocate node features array\n",
    "        sample_nodes = np.zeros((33, 23), dtype=np.float32)\n",
    "        \n",
    "        for pos in range(33):\n",
    "            if pos in is_padded:\n",
    "                continue  # Keep zeros for padded positions\n",
    "            \n",
    "            feature_idx = 0\n",
    "            \n",
    "            # Backbone angles\n",
    "            for angle in ['phi', 'psi', 'omega']:\n",
    "                angle_vals = np.array(eval(row[angle]))\n",
    "                angle_rad = np.pi * angle_vals[pos] / 180.0\n",
    "                sample_nodes[pos, feature_idx:feature_idx+2] = [np.sin(angle_rad), np.cos(angle_rad)]\n",
    "                feature_idx += 2\n",
    "            \n",
    "            # SASA\n",
    "            sasa_vals = np.array(eval(row['sasa']))\n",
    "            sample_nodes[pos, feature_idx] = sasa_vals[pos]\n",
    "            feature_idx += 1\n",
    "            \n",
    "            # SS\n",
    "            ss_val = row['ss'][pos]\n",
    "            ss_onehot = [1 if ss_val == ss_type else 0 for ss_type in 'HEL']\n",
    "            sample_nodes[pos, feature_idx:feature_idx+3] = ss_onehot\n",
    "            feature_idx += 3\n",
    "            \n",
    "            # plDDT\n",
    "            plddt_vals = np.array(eval(row['plDDT']))\n",
    "            sample_nodes[pos, feature_idx] = plddt_vals[pos]\n",
    "            feature_idx += 1\n",
    "            \n",
    "            # Chi angles\n",
    "            for chi in ['chi1', 'chi2', 'chi3', 'chi4']:\n",
    "                chi_vals = np.array(eval(row[chi]))\n",
    "                chi_rad = np.pi * chi_vals[pos] / 180.0\n",
    "                sample_nodes[pos, feature_idx:feature_idx+2] = [np.sin(chi_rad), np.cos(chi_rad)]\n",
    "                feature_idx += 2\n",
    "            \n",
    "            # K-relative features\n",
    "            sample_nodes[pos, feature_idx] = abs(pos - K_POS) / 16.0  # Distance to K\n",
    "            feature_idx += 1\n",
    "            sample_nodes[pos, feature_idx] = float(pos == K_POS)  # Is K position\n",
    "            feature_idx += 1\n",
    "            sample_nodes[pos, feature_idx] = float(sequence[pos] == 'K')  # Is K amino acid\n",
    "        \n",
    "        # Create edges\n",
    "        dist_map = np.array(eval(row['distance_map'])).reshape(33, 33)\n",
    "        edges = []\n",
    "        edge_attrs = []\n",
    "        \n",
    "        # Pre-calculate SASA values\n",
    "        sasa_vals = np.array(eval(row['sasa']))\n",
    "        \n",
    "        for i in range(33):\n",
    "            if i in is_padded:\n",
    "                continue\n",
    "                \n",
    "            for j in range(33):\n",
    "                if j in is_padded or i == j:\n",
    "                    continue\n",
    "                    \n",
    "                if dist_map[i,j] != -1 and dist_map[i,j] < threshold:\n",
    "                    edges.append([i, j])\n",
    "                    edge_attrs.append(\n",
    "                        create_edge_features(\n",
    "                            i, j, dist_map, sequence, row['ss'], \n",
    "                            sasa_vals, K_POS\n",
    "                        )\n",
    "                    )\n",
    "        \n",
    "        # Pad or truncate edges\n",
    "        if len(edges) == 0:\n",
    "            # Handle case with no edges\n",
    "            edges = np.zeros((max_edges, 2), dtype=np.float32)\n",
    "            edge_attrs = np.zeros((max_edges, 18), dtype=np.float32)\n",
    "            edge_mask = np.zeros(max_edges, dtype=np.float32)\n",
    "        else:\n",
    "            if len(edges) > max_edges:\n",
    "                # Prioritize K-connected edges\n",
    "                k_connected = [(idx, edge) for idx, edge in enumerate(edges) \n",
    "                             if K_POS in edge]\n",
    "                other_edges = [(idx, edge) for idx, edge in enumerate(edges) \n",
    "                             if K_POS not in edge]\n",
    "                \n",
    "                k_connected.sort(key=lambda x: edge_attrs[x[0]][4], reverse=True)\n",
    "                other_edges.sort(key=lambda x: edge_attrs[x[0]][4], reverse=True)\n",
    "                \n",
    "                keep_indices = [idx for idx, _ in (k_connected + other_edges)][:max_edges]\n",
    "                edges = [edges[i] for i in keep_indices]\n",
    "                edge_attrs = [edge_attrs[i] for i in keep_indices]\n",
    "                \n",
    "                # Convert to fixed-size arrays\n",
    "                edges = np.array(edges, dtype=np.float32)\n",
    "                edge_attrs = np.array(edge_attrs, dtype=np.float32)\n",
    "                edge_mask = np.ones(max_edges, dtype=np.float32)\n",
    "            else:\n",
    "                # Pad arrays\n",
    "                num_edges = len(edges)\n",
    "                pad_edges = np.zeros((max_edges - num_edges, 2), dtype=np.float32)\n",
    "                pad_attrs = np.zeros((max_edges - num_edges, 18), dtype=np.float32)\n",
    "                \n",
    "                edges = np.concatenate([np.array(edges, dtype=np.float32), pad_edges], axis=0)\n",
    "                edge_attrs = np.concatenate([np.array(edge_attrs, dtype=np.float32), pad_attrs], axis=0)\n",
    "                edge_mask = np.concatenate([\n",
    "                    np.ones(num_edges, dtype=np.float32),\n",
    "                    np.zeros(max_edges - num_edges, dtype=np.float32)\n",
    "                ])\n",
    "        \n",
    "        # Create node mask\n",
    "        node_mask = np.array([0.0 if pos in is_padded else 1.0 for pos in range(33)], dtype=np.float32)\n",
    "        \n",
    "        node_features_list.append(sample_nodes)\n",
    "        edge_indices_list.append(edges)\n",
    "        edge_features_list.append(edge_attrs)\n",
    "        node_masks_list.append(node_mask)\n",
    "        edge_masks_list.append(edge_mask)\n",
    "        \n",
    "        if idx % 1000 == 0:\n",
    "            print(f\"Processed {idx}/{len(df)} samples\")\n",
    "    \n",
    "    # Convert to numpy arrays with consistent shapes\n",
    "    node_features = np.stack(node_features_list, axis=0)\n",
    "    edge_indices = np.stack(edge_indices_list, axis=0)\n",
    "    edge_features = np.stack(edge_features_list, axis=0)\n",
    "    node_masks = np.stack(node_masks_list, axis=0)\n",
    "    edge_masks = np.stack(edge_masks_list, axis=0)\n",
    "    \n",
    "    print(f\"\\nFinal shapes:\")\n",
    "    print(f\"Node features: {node_features.shape}\")\n",
    "    print(f\"Edge indices: {edge_indices.shape}\")\n",
    "    print(f\"Edge features: {edge_features.shape}\")\n",
    "    print(f\"Node masks: {node_masks.shape}\")\n",
    "    print(f\"Edge masks: {edge_masks.shape}\")\n",
    "    \n",
    "    return node_features, edge_indices, edge_features, node_masks, edge_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hybrid_model(gnn_type='simple', seq_length=33, node_features=23, max_nodes=33, max_edges=300):\n",
    "    \"\"\"\n",
    "    Create hybrid model with sequence CNN and choice of GNN\n",
    "    gnn_type: 'simple', 'gcn', or 'gat'\n",
    "    \"\"\"\n",
    "    regularizer = tf.keras.regularizers.l2(0.01)\n",
    "    \n",
    "    # Sequence track (CNN)\n",
    "    seq_input = tf.keras.layers.Input(shape=(seq_length,), name='sequence_input')\n",
    "    x_seq = tf.keras.layers.Embedding(21, 21)(seq_input)\n",
    "    x_seq = tf.keras.layers.Reshape((seq_length, 21, 1))(x_seq)\n",
    "    x_seq = tf.keras.layers.Conv2D(32, kernel_size=(17, 3), activation='relu', padding='valid')(x_seq)\n",
    "    x_seq = tf.keras.layers.BatchNormalization()(x_seq)\n",
    "    x_seq = tf.keras.layers.Dropout(0.4)(x_seq)\n",
    "    x_seq = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x_seq)\n",
    "    x_seq = tf.keras.layers.Flatten()(x_seq)\n",
    "    x_seq = tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=regularizer)(x_seq)\n",
    "    \n",
    "    # GNN track\n",
    "    node_input = tf.keras.layers.Input(shape=(max_nodes, node_features), dtype=tf.float32, name='node_features')\n",
    "    edge_index_input = tf.keras.layers.Input(shape=(max_edges, 2), dtype=tf.float32, name='edge_index')\n",
    "    edge_feature_input = tf.keras.layers.Input(shape=(max_edges, 18), dtype=tf.float32, name='edge_features')\n",
    "    node_mask_input = tf.keras.layers.Input(shape=(max_nodes,), dtype=tf.float32, name='node_mask')\n",
    "    edge_mask_input = tf.keras.layers.Input(shape=(max_edges,), dtype=tf.float32, name='edge_mask')\n",
    "    \n",
    "    # GNN layers based on type\n",
    "    x_gnn = node_input\n",
    "    if gnn_type == 'simple':\n",
    "        GNNLayer = SimpleGNNLayer\n",
    "    elif gnn_type == 'gcn':\n",
    "        GNNLayer = GCNLayer\n",
    "    else:  # gat\n",
    "        GNNLayer = GATLayer\n",
    "    \n",
    "    # Single GNN layer\n",
    "    x_gnn = GNNLayer(32)([x_gnn, edge_index_input, edge_feature_input, node_mask_input, edge_mask_input])\n",
    "    x_gnn = tf.keras.layers.GlobalAveragePooling1D()(x_gnn)\n",
    "    \n",
    "    # Combine tracks\n",
    "    combined = tf.keras.layers.Concatenate()([x_seq, x_gnn])\n",
    "    \n",
    "    # Final classification\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizer)(combined)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = tf.keras.Model(\n",
    "        inputs=[seq_input, node_input, edge_index_input, edge_feature_input, node_mask_input, edge_mask_input],\n",
    "        outputs=outputs\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPooling(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention_dense = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "    def call(self, inputs, mask=None):\n",
    "        x, node_mask = inputs\n",
    "        attention_weights = self.attention_dense(x)\n",
    "        attention_weights = attention_weights * tf.expand_dims(node_mask, -1)\n",
    "        return tf.reduce_sum(x * attention_weights, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence_data(df):\n",
    "    \"\"\"Convert sequences to integer encoding\"\"\"\n",
    "    alphabet = 'ARNDCQEGHILKMFPSTWYV-'\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    \n",
    "    sequences = df['sequence'].values\n",
    "    encodings = []\n",
    "    \n",
    "    for seq in sequences:\n",
    "        try:\n",
    "            integer_encoded = [char_to_int[char] for char in seq]\n",
    "            encodings.append(integer_encoded)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sequence: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return np.array(encodings, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_true, y_pred):\n",
    "    \"\"\"Print comprehensive evaluation metrics\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    sensitivity = cm[1][1]/(cm[1][1]+cm[1][0])\n",
    "    specificity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
    "    print(f\"MCC: {mcc:.4f}\")\n",
    "    print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "    print(f\"Specificity: {specificity:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_cv(train_df, test_df, threshold=8.0, gnn_type=None):\n",
    "    \"\"\"\n",
    "    Training function with cross-validation\n",
    "    Args:\n",
    "        train_df: training dataframe\n",
    "        test_df: test dataframe\n",
    "        threshold: distance threshold for edge creation\n",
    "        gnn_type: 'simple', 'gcn', 'gat', or None (will try all)\n",
    "    \"\"\"\n",
    "    # Prepare data once\n",
    "    print(\"Preparing sequence data...\")\n",
    "    \n",
    "    train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    X_train_seq = prepare_sequence_data(train_df)\n",
    "    X_test_seq = prepare_sequence_data(test_df)\n",
    "    \n",
    "    print(\"Preparing GNN data...\")\n",
    "    (train_node_features, train_edge_indices, train_edge_features,\n",
    "     train_node_masks, train_edge_masks) = prepare_gnn_data(train_df, threshold=threshold)\n",
    "    \n",
    "    (test_node_features, test_edge_indices, test_edge_features,\n",
    "     test_node_masks, test_edge_masks) = prepare_gnn_data(test_df, threshold=threshold)\n",
    "    \n",
    "    y_train = train_df['label'].values\n",
    "    y_test = test_df['label'].values\n",
    "    \n",
    "    # Print class distribution\n",
    "    print(\"\\nClass distribution:\")\n",
    "    print(\"Train:\", np.bincount(y_train))\n",
    "    print(\"Test:\", np.bincount(y_test))\n",
    "    \n",
    "    # Define which GNN types to try\n",
    "    if gnn_type is None:\n",
    "        gnn_types = ['simple', 'gcn', 'gat']\n",
    "    else:\n",
    "        gnn_types = [gnn_type]\n",
    "    \n",
    "    # Store results for all types\n",
    "    all_results = {}\n",
    "    \n",
    "    for gnn_type in gnn_types:\n",
    "        print(f\"\\nTraining {gnn_type.upper()} model\")\n",
    "        \n",
    "        # Cross-validation\n",
    "        kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        metrics = {\n",
    "            'accuracy': [], 'balanced_accuracy': [], \n",
    "            'mcc': [], 'sensitivity': [], 'specificity': []\n",
    "        }\n",
    "        test_predictions = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train_seq, y_train), 1):\n",
    "            print(f\"\\nFold {fold}/5\")\n",
    "            \n",
    "            # Calculate class weights\n",
    "            total = len(train_idx)\n",
    "            pos = np.sum(y_train[train_idx] == 1)\n",
    "            neg = np.sum(y_train[train_idx] == 0)\n",
    "            class_weights = {\n",
    "                0: total / (2 * neg),\n",
    "                1: total / (2 * pos)\n",
    "            }\n",
    "            \n",
    "            # Create and compile model\n",
    "            model = create_hybrid_model(\n",
    "                gnn_type=gnn_type,\n",
    "                seq_length=33,\n",
    "                node_features=train_node_features.shape[-1],\n",
    "                max_nodes=train_node_features.shape[1],\n",
    "                max_edges=train_edge_indices.shape[1]\n",
    "            )\n",
    "            \n",
    "            model.compile(\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "            \n",
    "            # Callbacks\n",
    "            callbacks = [\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    patience=7,\n",
    "                    restore_best_weights=True\n",
    "                ),\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                    monitor='val_loss',\n",
    "                    factor=0.5,\n",
    "                    patience=4,\n",
    "                    min_lr=1e-6\n",
    "                )\n",
    "            ]\n",
    "            \n",
    "            # Train\n",
    "            history = model.fit(\n",
    "                [\n",
    "                    X_train_seq[train_idx],\n",
    "                    train_node_features[train_idx],\n",
    "                    train_edge_indices[train_idx],\n",
    "                    train_edge_features[train_idx],\n",
    "                    train_node_masks[train_idx],\n",
    "                    train_edge_masks[train_idx]\n",
    "                ],\n",
    "                y_train[train_idx],\n",
    "                validation_data=(\n",
    "                    [\n",
    "                        X_train_seq[val_idx],\n",
    "                        train_node_features[val_idx],\n",
    "                        train_edge_indices[val_idx],\n",
    "                        train_edge_features[val_idx],\n",
    "                        train_node_masks[val_idx],\n",
    "                        train_edge_masks[val_idx]\n",
    "                    ],\n",
    "                    y_train[val_idx]\n",
    "                ),\n",
    "                batch_size=32,\n",
    "                epochs=50,\n",
    "                callbacks=callbacks,\n",
    "                class_weight=class_weights,\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            # Evaluate on validation set\n",
    "            val_pred = model.predict(\n",
    "                [\n",
    "                    X_train_seq[val_idx],\n",
    "                    train_node_features[val_idx],\n",
    "                    train_edge_indices[val_idx],\n",
    "                    train_edge_features[val_idx],\n",
    "                    train_node_masks[val_idx],\n",
    "                    train_edge_masks[val_idx]\n",
    "                ]\n",
    "            )\n",
    "            val_pred_binary = (val_pred > 0.5).astype(int)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            acc = accuracy_score(y_train[val_idx], val_pred_binary)\n",
    "            balanced_acc = balanced_accuracy_score(y_train[val_idx], val_pred_binary)\n",
    "            mcc = matthews_corrcoef(y_train[val_idx], val_pred_binary)\n",
    "            cm = confusion_matrix(y_train[val_idx], val_pred_binary)\n",
    "            sensitivity = cm[1][1]/(cm[1][1]+cm[1][0]) if (cm[1][1]+cm[1][0]) > 0 else 0\n",
    "            specificity = cm[0][0]/(cm[0][0]+cm[0][1]) if (cm[0][0]+cm[0][1]) > 0 else 0\n",
    "            \n",
    "            metrics['accuracy'].append(acc)\n",
    "            metrics['balanced_accuracy'].append(balanced_acc)\n",
    "            metrics['mcc'].append(mcc)\n",
    "            metrics['sensitivity'].append(sensitivity)\n",
    "            metrics['specificity'].append(specificity)\n",
    "            \n",
    "            # Predict on test set\n",
    "            test_pred = model.predict(\n",
    "                [\n",
    "                    X_test_seq,\n",
    "                    test_node_features,\n",
    "                    test_edge_indices,\n",
    "                    test_edge_features,\n",
    "                    test_node_masks,\n",
    "                    test_edge_masks\n",
    "                ]\n",
    "            )\n",
    "            test_predictions.append(test_pred)\n",
    "            \n",
    "            # Print fold results\n",
    "            print(f\"\\nFold {fold} Results:\")\n",
    "            print(f\"Accuracy: {acc:.4f}\")\n",
    "            print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
    "            print(f\"MCC: {mcc:.4f}\")\n",
    "            print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "            print(f\"Specificity: {specificity:.4f}\")\n",
    "            print(\"Confusion Matrix:\")\n",
    "            print(cm)\n",
    "        \n",
    "        # Print average CV results\n",
    "        print(f\"\\nAverage Cross-validation Results for {gnn_type.upper()}:\")\n",
    "        cv_results = {}\n",
    "        for metric in metrics:\n",
    "            mean = np.mean(metrics[metric])\n",
    "            std = np.std(metrics[metric])\n",
    "            print(f\"{metric}: {mean:.4f} ± {std:.4f}\")\n",
    "            cv_results[metric] = {'mean': mean, 'std': std}\n",
    "        \n",
    "        # Ensemble predictions on test set\n",
    "        test_pred_avg = np.mean(test_predictions, axis=0)\n",
    "        test_pred_binary = (test_pred_avg > 0.5).astype(int)\n",
    "        \n",
    "        # Print final test results\n",
    "        print(f\"\\nFinal Test Set Results for {gnn_type.upper()}:\")\n",
    "        test_results = print_metrics(y_test, test_pred_binary)\n",
    "        \n",
    "        # Store results\n",
    "        all_results[gnn_type] = {\n",
    "            'cv_results': cv_results,\n",
    "            'test_results': test_results,\n",
    "            'model': model\n",
    "        }\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing sequence data...\n",
      "Preparing GNN data...\n",
      "Processing samples for GNN...\n",
      "Processed 0/8853 samples\n",
      "Processed 1000/8853 samples\n",
      "Processed 2000/8853 samples\n",
      "Processed 3000/8853 samples\n",
      "Processed 4000/8853 samples\n",
      "Processed 5000/8853 samples\n",
      "Processed 6000/8853 samples\n",
      "Processed 7000/8853 samples\n",
      "Processed 8000/8853 samples\n",
      "\n",
      "Final shapes:\n",
      "Node features: (8853, 33, 23)\n",
      "Edge indices: (8853, 300, 2)\n",
      "Edge features: (8853, 300, 18)\n",
      "Node masks: (8853, 33)\n",
      "Edge masks: (8853, 300)\n",
      "Processing samples for GNN...\n",
      "Processed 0/2737 samples\n",
      "Processed 1000/2737 samples\n",
      "Processed 2000/2737 samples\n",
      "\n",
      "Final shapes:\n",
      "Node features: (2737, 33, 23)\n",
      "Edge indices: (2737, 300, 2)\n",
      "Edge features: (2737, 300, 18)\n",
      "Node masks: (2737, 33)\n",
      "Edge masks: (2737, 300)\n",
      "\n",
      "Class distribution:\n",
      "Train: [4261 4592]\n",
      "Test: [2497  240]\n",
      "\n",
      "Training SIMPLE model\n",
      "\n",
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1740156621.594509  810749 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:00:06.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:50:24.211377: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_21}}\n",
      "E0000 00:00:1740156626.249307  810749 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1/dropout_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "I0000 00:00:1740156627.035935  812863 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5339 - loss: 1.3410"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:50:30.395057: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_20}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.5340 - loss: 1.3359 - val_accuracy: 0.5652 - val_loss: 0.8367 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5470 - loss: 0.7889 - val_accuracy: 0.5833 - val_loss: 0.7180 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5568 - loss: 0.7427 - val_accuracy: 0.5714 - val_loss: 0.7114 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5451 - loss: 0.7278 - val_accuracy: 0.4811 - val_loss: 0.7812 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5655 - loss: 0.7116 - val_accuracy: 0.5827 - val_loss: 0.6936 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5695 - loss: 0.6988 - val_accuracy: 0.4946 - val_loss: 0.7161 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5691 - loss: 0.6985 - val_accuracy: 0.4811 - val_loss: 1.0292 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5746 - loss: 0.6933 - val_accuracy: 0.4811 - val_loss: 0.7370 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5747 - loss: 0.6866 - val_accuracy: 0.4828 - val_loss: 0.7200 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5792 - loss: 0.6853 - val_accuracy: 0.5319 - val_loss: 0.6942 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5776 - loss: 0.6822 - val_accuracy: 0.5116 - val_loss: 0.6980 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5846 - loss: 0.6812 - val_accuracy: 0.4811 - val_loss: 0.7954 - learning_rate: 5.0000e-04\n",
      "\u001b[1m18/56\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:50:53.373917: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_19}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Fold 1 Results:\n",
      "Accuracy: 0.5827\n",
      "Balanced Accuracy: 0.5741\n",
      "MCC: 0.1668\n",
      "Sensitivity: 0.8009\n",
      "Specificity: 0.3474\n",
      "Confusion Matrix:\n",
      "[[296 556]\n",
      " [183 736]]\n",
      "\n",
      "Fold 2/5\n",
      "Epoch 1/50\n",
      "\u001b[1m216/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5248 - loss: 1.3320"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:50:59.731879: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_20}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.5249 - loss: 1.3236 - val_accuracy: 0.5703 - val_loss: 0.8126 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5485 - loss: 0.8093 - val_accuracy: 0.5884 - val_loss: 0.7334 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5630 - loss: 0.7492 - val_accuracy: 0.5850 - val_loss: 0.7157 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5460 - loss: 0.7334 - val_accuracy: 0.5788 - val_loss: 0.7054 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5683 - loss: 0.7122 - val_accuracy: 0.5714 - val_loss: 0.7053 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5740 - loss: 0.7074 - val_accuracy: 0.4850 - val_loss: 0.7220 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5662 - loss: 0.7040 - val_accuracy: 0.4811 - val_loss: 0.9326 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5540 - loss: 0.7041 - val_accuracy: 0.5076 - val_loss: 0.7057 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5639 - loss: 0.6984 - val_accuracy: 0.5415 - val_loss: 0.6967 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5793 - loss: 0.6900 - val_accuracy: 0.5330 - val_loss: 0.6961 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5848 - loss: 0.6893 - val_accuracy: 0.5624 - val_loss: 0.6881 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5694 - loss: 0.6902 - val_accuracy: 0.5997 - val_loss: 0.6774 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5885 - loss: 0.6889 - val_accuracy: 0.5771 - val_loss: 0.6837 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5754 - loss: 0.6856 - val_accuracy: 0.5596 - val_loss: 0.6856 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5842 - loss: 0.6842 - val_accuracy: 0.5901 - val_loss: 0.6772 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5809 - loss: 0.6819 - val_accuracy: 0.5805 - val_loss: 0.6803 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5835 - loss: 0.6834 - val_accuracy: 0.5596 - val_loss: 0.6849 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5742 - loss: 0.6824 - val_accuracy: 0.5003 - val_loss: 0.6911 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5787 - loss: 0.6836 - val_accuracy: 0.5923 - val_loss: 0.6720 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5832 - loss: 0.6791 - val_accuracy: 0.5189 - val_loss: 0.6866 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5727 - loss: 0.6841 - val_accuracy: 0.5844 - val_loss: 0.6747 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5842 - loss: 0.6796 - val_accuracy: 0.5850 - val_loss: 0.6728 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5765 - loss: 0.6796 - val_accuracy: 0.5822 - val_loss: 0.6712 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5794 - loss: 0.6810 - val_accuracy: 0.5234 - val_loss: 0.6869 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5877 - loss: 0.6778 - val_accuracy: 0.4811 - val_loss: 0.7321 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5927 - loss: 0.6734 - val_accuracy: 0.5709 - val_loss: 0.6755 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5837 - loss: 0.6755 - val_accuracy: 0.5980 - val_loss: 0.6698 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5854 - loss: 0.6791 - val_accuracy: 0.6053 - val_loss: 0.6643 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5895 - loss: 0.6733 - val_accuracy: 0.5878 - val_loss: 0.6716 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5987 - loss: 0.6733 - val_accuracy: 0.5985 - val_loss: 0.6635 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5979 - loss: 0.6727 - val_accuracy: 0.5234 - val_loss: 0.6813 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5982 - loss: 0.6701 - val_accuracy: 0.6160 - val_loss: 0.6650 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6037 - loss: 0.6710 - val_accuracy: 0.5652 - val_loss: 0.8147 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5948 - loss: 0.6743 - val_accuracy: 0.5426 - val_loss: 0.6784 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6005 - loss: 0.6670 - val_accuracy: 0.6070 - val_loss: 0.6630 - learning_rate: 2.5000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6081 - loss: 0.6655 - val_accuracy: 0.6121 - val_loss: 0.6633 - learning_rate: 2.5000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5883 - loss: 0.6681 - val_accuracy: 0.6172 - val_loss: 0.6574 - learning_rate: 2.5000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6018 - loss: 0.6664 - val_accuracy: 0.6166 - val_loss: 0.6591 - learning_rate: 2.5000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6067 - loss: 0.6651 - val_accuracy: 0.6126 - val_loss: 0.6597 - learning_rate: 2.5000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6123 - loss: 0.6613 - val_accuracy: 0.5415 - val_loss: 0.6809 - learning_rate: 2.5000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6109 - loss: 0.6640 - val_accuracy: 0.5968 - val_loss: 0.6637 - learning_rate: 2.5000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6203 - loss: 0.6585 - val_accuracy: 0.6279 - val_loss: 0.6520 - learning_rate: 1.2500e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6131 - loss: 0.6606 - val_accuracy: 0.6296 - val_loss: 0.6521 - learning_rate: 1.2500e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6188 - loss: 0.6606 - val_accuracy: 0.5471 - val_loss: 0.6749 - learning_rate: 1.2500e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6160 - loss: 0.6617 - val_accuracy: 0.5923 - val_loss: 0.6646 - learning_rate: 1.2500e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6191 - loss: 0.6586 - val_accuracy: 0.5596 - val_loss: 0.6756 - learning_rate: 1.2500e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6220 - loss: 0.6584 - val_accuracy: 0.6313 - val_loss: 0.6519 - learning_rate: 6.2500e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6197 - loss: 0.6580 - val_accuracy: 0.6347 - val_loss: 0.6498 - learning_rate: 6.2500e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6220 - loss: 0.6548 - val_accuracy: 0.6318 - val_loss: 0.6496 - learning_rate: 6.2500e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6212 - loss: 0.6571 - val_accuracy: 0.6262 - val_loss: 0.6530 - learning_rate: 6.2500e-05\n",
      "\u001b[1m16/56\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:52:45.584156: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_19}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "Fold 2 Results:\n",
      "Accuracy: 0.6318\n",
      "Balanced Accuracy: 0.6289\n",
      "MCC: 0.2612\n",
      "Sensitivity: 0.7073\n",
      "Specificity: 0.5505\n",
      "Confusion Matrix:\n",
      "[[469 383]\n",
      " [269 650]]\n",
      "\n",
      "Fold 3/5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1740156769.560423  810749 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_2_1/dropout_4_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m216/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5286 - loss: 1.2848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:52:51.722726: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_20}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.5287 - loss: 1.2764 - val_accuracy: 0.4816 - val_loss: 2.5536 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5369 - loss: 0.7826 - val_accuracy: 0.4816 - val_loss: 0.9512 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5501 - loss: 0.7353 - val_accuracy: 0.4816 - val_loss: 0.8871 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5618 - loss: 0.7138 - val_accuracy: 0.5567 - val_loss: 0.6980 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5687 - loss: 0.6991 - val_accuracy: 0.5528 - val_loss: 0.6951 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5713 - loss: 0.6962 - val_accuracy: 0.5184 - val_loss: 0.9083 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5794 - loss: 0.6934 - val_accuracy: 0.4816 - val_loss: 6.9179 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 0.6929 - val_accuracy: 0.4816 - val_loss: 0.7114 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5834 - loss: 0.6869 - val_accuracy: 0.4816 - val_loss: 0.7049 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5831 - loss: 0.6848 - val_accuracy: 0.5025 - val_loss: 0.6951 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5818 - loss: 0.6825 - val_accuracy: 0.4816 - val_loss: 0.7346 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5870 - loss: 0.6811 - val_accuracy: 0.5330 - val_loss: 0.6878 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5884 - loss: 0.6818 - val_accuracy: 0.5438 - val_loss: 0.6861 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5866 - loss: 0.6818 - val_accuracy: 0.4896 - val_loss: 0.6980 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5765 - loss: 0.6853 - val_accuracy: 0.5974 - val_loss: 0.6727 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5834 - loss: 0.6801 - val_accuracy: 0.5748 - val_loss: 0.6780 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5826 - loss: 0.6790 - val_accuracy: 0.5884 - val_loss: 0.6744 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5830 - loss: 0.6799 - val_accuracy: 0.5618 - val_loss: 0.6806 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5921 - loss: 0.6768 - val_accuracy: 0.5398 - val_loss: 0.6828 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5804 - loss: 0.6786 - val_accuracy: 0.5483 - val_loss: 0.6816 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5868 - loss: 0.6780 - val_accuracy: 0.5240 - val_loss: 0.6838 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5904 - loss: 0.6759 - val_accuracy: 0.5985 - val_loss: 0.6693 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5844 - loss: 0.6771 - val_accuracy: 0.5850 - val_loss: 0.6748 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5863 - loss: 0.6744 - val_accuracy: 0.5923 - val_loss: 0.6728 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5839 - loss: 0.6766 - val_accuracy: 0.5833 - val_loss: 0.6735 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5852 - loss: 0.6755 - val_accuracy: 0.5065 - val_loss: 0.6872 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5839 - loss: 0.6753 - val_accuracy: 0.5918 - val_loss: 0.6707 - learning_rate: 1.2500e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5917 - loss: 0.6729 - val_accuracy: 0.5968 - val_loss: 0.6696 - learning_rate: 1.2500e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5919 - loss: 0.6736 - val_accuracy: 0.5816 - val_loss: 0.6727 - learning_rate: 1.2500e-04\n",
      "\u001b[1m17/56\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:53:50.887422: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_19}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "Fold 3 Results:\n",
      "Accuracy: 0.5985\n",
      "Balanced Accuracy: 0.5957\n",
      "MCC: 0.1938\n",
      "Sensitivity: 0.6721\n",
      "Specificity: 0.5193\n",
      "Confusion Matrix:\n",
      "[[443 410]\n",
      " [301 617]]\n",
      "\n",
      "Fold 4/5\n",
      "Epoch 1/50\n",
      "\u001b[1m  1/222\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:31\u001b[0m 2s/step - accuracy: 0.5312 - loss: 2.2253"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1740156834.982181  810749 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_3_1/dropout_6_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5337 - loss: 1.3483"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:53:57.182194: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_20}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.5337 - loss: 1.3471 - val_accuracy: 0.4814 - val_loss: 1.7611 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5431 - loss: 0.8139 - val_accuracy: 0.5740 - val_loss: 0.7480 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5498 - loss: 0.7570 - val_accuracy: 0.4960 - val_loss: 0.7574 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5639 - loss: 0.7276 - val_accuracy: 0.5497 - val_loss: 0.7597 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5746 - loss: 0.7135 - val_accuracy: 0.5565 - val_loss: 0.7098 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5655 - loss: 0.7092 - val_accuracy: 0.5627 - val_loss: 0.7029 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5755 - loss: 0.6962 - val_accuracy: 0.5706 - val_loss: 0.6973 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5862 - loss: 0.6900 - val_accuracy: 0.5689 - val_loss: 0.7037 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5877 - loss: 0.6863 - val_accuracy: 0.5723 - val_loss: 0.6943 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5815 - loss: 0.6842 - val_accuracy: 0.5780 - val_loss: 0.6910 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5879 - loss: 0.6821 - val_accuracy: 0.5362 - val_loss: 0.6955 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5837 - loss: 0.6821 - val_accuracy: 0.5740 - val_loss: 0.6858 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5839 - loss: 0.6796 - val_accuracy: 0.5695 - val_loss: 0.6956 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5957 - loss: 0.6740 - val_accuracy: 0.5689 - val_loss: 0.6909 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5895 - loss: 0.6770 - val_accuracy: 0.5734 - val_loss: 0.6875 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5958 - loss: 0.6732 - val_accuracy: 0.5661 - val_loss: 0.6868 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5906 - loss: 0.6706 - val_accuracy: 0.5695 - val_loss: 0.6825 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5934 - loss: 0.6700 - val_accuracy: 0.5768 - val_loss: 0.6801 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6021 - loss: 0.6698 - val_accuracy: 0.5650 - val_loss: 0.6837 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5969 - loss: 0.6719 - val_accuracy: 0.5757 - val_loss: 0.6895 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6016 - loss: 0.6691 - val_accuracy: 0.5825 - val_loss: 0.6777 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6061 - loss: 0.6670 - val_accuracy: 0.5876 - val_loss: 0.6745 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6072 - loss: 0.6645 - val_accuracy: 0.5842 - val_loss: 0.6758 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6099 - loss: 0.6655 - val_accuracy: 0.5322 - val_loss: 0.6967 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5956 - loss: 0.6660 - val_accuracy: 0.5554 - val_loss: 0.7247 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6098 - loss: 0.6657 - val_accuracy: 0.5757 - val_loss: 0.7015 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6096 - loss: 0.6635 - val_accuracy: 0.5977 - val_loss: 0.6717 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6134 - loss: 0.6609 - val_accuracy: 0.5938 - val_loss: 0.6708 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6128 - loss: 0.6594 - val_accuracy: 0.5898 - val_loss: 0.6690 - learning_rate: 2.5000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6128 - loss: 0.6625 - val_accuracy: 0.5955 - val_loss: 0.6697 - learning_rate: 2.5000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6162 - loss: 0.6589 - val_accuracy: 0.5960 - val_loss: 0.6694 - learning_rate: 2.5000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6178 - loss: 0.6579 - val_accuracy: 0.5898 - val_loss: 0.6723 - learning_rate: 2.5000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6135 - loss: 0.6578 - val_accuracy: 0.5847 - val_loss: 0.6759 - learning_rate: 2.5000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6188 - loss: 0.6567 - val_accuracy: 0.6034 - val_loss: 0.6642 - learning_rate: 1.2500e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6204 - loss: 0.6540 - val_accuracy: 0.6073 - val_loss: 0.6628 - learning_rate: 1.2500e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6246 - loss: 0.6540 - val_accuracy: 0.6068 - val_loss: 0.6623 - learning_rate: 1.2500e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6276 - loss: 0.6526 - val_accuracy: 0.6028 - val_loss: 0.6621 - learning_rate: 1.2500e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6318 - loss: 0.6510 - val_accuracy: 0.6616 - val_loss: 0.6391 - learning_rate: 1.2500e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6894 - loss: 0.6187 - val_accuracy: 0.6356 - val_loss: 0.6547 - learning_rate: 1.2500e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7100 - loss: 0.5950 - val_accuracy: 0.6655 - val_loss: 0.6276 - learning_rate: 1.2500e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7370 - loss: 0.5698 - val_accuracy: 0.6966 - val_loss: 0.5923 - learning_rate: 1.2500e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7577 - loss: 0.5428 - val_accuracy: 0.7000 - val_loss: 0.5860 - learning_rate: 1.2500e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7634 - loss: 0.5277 - val_accuracy: 0.7040 - val_loss: 0.5848 - learning_rate: 1.2500e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7755 - loss: 0.5244 - val_accuracy: 0.7237 - val_loss: 0.5706 - learning_rate: 1.2500e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7814 - loss: 0.5075 - val_accuracy: 0.7379 - val_loss: 0.5589 - learning_rate: 1.2500e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7851 - loss: 0.5039 - val_accuracy: 0.7384 - val_loss: 0.5624 - learning_rate: 1.2500e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7875 - loss: 0.4956 - val_accuracy: 0.7407 - val_loss: 0.5566 - learning_rate: 1.2500e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7920 - loss: 0.4865 - val_accuracy: 0.7492 - val_loss: 0.5476 - learning_rate: 1.2500e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7947 - loss: 0.4787 - val_accuracy: 0.7520 - val_loss: 0.5406 - learning_rate: 1.2500e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7979 - loss: 0.4757 - val_accuracy: 0.7356 - val_loss: 0.5626 - learning_rate: 1.2500e-04\n",
      "\u001b[1m18/56\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:55:41.081487: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_19}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Fold 4 Results:\n",
      "Accuracy: 0.7520\n",
      "Balanced Accuracy: 0.7482\n",
      "MCC: 0.5085\n",
      "Sensitivity: 0.8486\n",
      "Specificity: 0.6479\n",
      "Confusion Matrix:\n",
      "[[552 300]\n",
      " [139 779]]\n",
      "\n",
      "Fold 5/5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1740156945.318519  810749 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_4_1/dropout_8_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m218/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5342 - loss: 1.3598"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:55:47.582433: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_20}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.5343 - loss: 1.3540 - val_accuracy: 0.5401 - val_loss: 0.9013 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5359 - loss: 0.8379 - val_accuracy: 0.4814 - val_loss: 0.7685 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5519 - loss: 0.7726 - val_accuracy: 0.5644 - val_loss: 0.7281 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5636 - loss: 0.7338 - val_accuracy: 0.5768 - val_loss: 0.7085 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5618 - loss: 0.7161 - val_accuracy: 0.5853 - val_loss: 0.7015 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5716 - loss: 0.7012 - val_accuracy: 0.5797 - val_loss: 0.6942 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5707 - loss: 0.6942 - val_accuracy: 0.4814 - val_loss: 1.1503 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5790 - loss: 0.6893 - val_accuracy: 0.4814 - val_loss: 0.7444 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5732 - loss: 0.6892 - val_accuracy: 0.5333 - val_loss: 0.6925 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5713 - loss: 0.6873 - val_accuracy: 0.4859 - val_loss: 0.7029 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5694 - loss: 0.6842 - val_accuracy: 0.5768 - val_loss: 0.6819 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5799 - loss: 0.6801 - val_accuracy: 0.5723 - val_loss: 0.6824 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5708 - loss: 0.6828 - val_accuracy: 0.5757 - val_loss: 0.6774 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5739 - loss: 0.6805 - val_accuracy: 0.5610 - val_loss: 0.6818 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5786 - loss: 0.6811 - val_accuracy: 0.5051 - val_loss: 0.6908 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5707 - loss: 0.6808 - val_accuracy: 0.5825 - val_loss: 0.6756 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5699 - loss: 0.6779 - val_accuracy: 0.5859 - val_loss: 0.6747 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5792 - loss: 0.6765 - val_accuracy: 0.5791 - val_loss: 0.6741 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5908 - loss: 0.6736 - val_accuracy: 0.5842 - val_loss: 0.6741 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5810 - loss: 0.6762 - val_accuracy: 0.5836 - val_loss: 0.6740 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5815 - loss: 0.6746 - val_accuracy: 0.5853 - val_loss: 0.6726 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5819 - loss: 0.6734 - val_accuracy: 0.5853 - val_loss: 0.6734 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5804 - loss: 0.6725 - val_accuracy: 0.5847 - val_loss: 0.6725 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5863 - loss: 0.6736 - val_accuracy: 0.5847 - val_loss: 0.6722 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5895 - loss: 0.6718 - val_accuracy: 0.5808 - val_loss: 0.6721 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5864 - loss: 0.6710 - val_accuracy: 0.5938 - val_loss: 0.6727 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5962 - loss: 0.6719 - val_accuracy: 0.5921 - val_loss: 0.6732 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5848 - loss: 0.6738 - val_accuracy: 0.5842 - val_loss: 0.6720 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5858 - loss: 0.6712 - val_accuracy: 0.5785 - val_loss: 0.6738 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5907 - loss: 0.6698 - val_accuracy: 0.5915 - val_loss: 0.6674 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5998 - loss: 0.6652 - val_accuracy: 0.5927 - val_loss: 0.6658 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5935 - loss: 0.6687 - val_accuracy: 0.5831 - val_loss: 0.6713 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5940 - loss: 0.6658 - val_accuracy: 0.5847 - val_loss: 0.6720 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6019 - loss: 0.6655 - val_accuracy: 0.5989 - val_loss: 0.6629 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6071 - loss: 0.6618 - val_accuracy: 0.5486 - val_loss: 0.6794 - learning_rate: 5.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6061 - loss: 0.6630 - val_accuracy: 0.5379 - val_loss: 0.6814 - learning_rate: 5.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6132 - loss: 0.6622 - val_accuracy: 0.5949 - val_loss: 0.6660 - learning_rate: 5.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6139 - loss: 0.6621 - val_accuracy: 0.5836 - val_loss: 0.6685 - learning_rate: 5.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6205 - loss: 0.6567 - val_accuracy: 0.6113 - val_loss: 0.6580 - learning_rate: 2.5000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6149 - loss: 0.6570 - val_accuracy: 0.5718 - val_loss: 0.6698 - learning_rate: 2.5000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6201 - loss: 0.6571 - val_accuracy: 0.6175 - val_loss: 0.6526 - learning_rate: 2.5000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6248 - loss: 0.6534 - val_accuracy: 0.6226 - val_loss: 0.6516 - learning_rate: 2.5000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6284 - loss: 0.6520 - val_accuracy: 0.5915 - val_loss: 0.6649 - learning_rate: 2.5000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6176 - loss: 0.6541 - val_accuracy: 0.5949 - val_loss: 0.6626 - learning_rate: 2.5000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6254 - loss: 0.6512 - val_accuracy: 0.6124 - val_loss: 0.6540 - learning_rate: 2.5000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6190 - loss: 0.6517 - val_accuracy: 0.6011 - val_loss: 0.6586 - learning_rate: 2.5000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6295 - loss: 0.6513 - val_accuracy: 0.6192 - val_loss: 0.6480 - learning_rate: 1.2500e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6282 - loss: 0.6495 - val_accuracy: 0.6232 - val_loss: 0.6473 - learning_rate: 1.2500e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6268 - loss: 0.6479 - val_accuracy: 0.6136 - val_loss: 0.6542 - learning_rate: 1.2500e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6317 - loss: 0.6491 - val_accuracy: 0.6164 - val_loss: 0.6484 - learning_rate: 1.2500e-04\n",
      "\u001b[1m17/56\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:57:32.911150: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_19}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "Fold 5 Results:\n",
      "Accuracy: 0.6232\n",
      "Balanced Accuracy: 0.6203\n",
      "MCC: 0.2437\n",
      "Sensitivity: 0.6961\n",
      "Specificity: 0.5446\n",
      "Confusion Matrix:\n",
      "[[464 388]\n",
      " [279 639]]\n",
      "\n",
      "Average Cross-validation Results for SIMPLE:\n",
      "accuracy: 0.6376 ± 0.0598\n",
      "balanced_accuracy: 0.6335 ± 0.0605\n",
      "mcc: 0.2748 ± 0.1216\n",
      "sensitivity: 0.7450 ± 0.0678\n",
      "specificity: 0.5219 ± 0.0976\n",
      "\n",
      "Final Test Set Results for SIMPLE:\n",
      "Accuracy: 0.6288\n",
      "Balanced Accuracy: 0.6855\n",
      "MCC: 0.2129\n",
      "Sensitivity: 0.7542\n",
      "Specificity: 0.6167\n",
      "Confusion Matrix:\n",
      "[[1540  957]\n",
      " [  59  181]]\n",
      "\n",
      "Training GCN model\n",
      "\n",
      "Fold 1/5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1740157056.676355  810749 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_5_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m218/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5461 - loss: 1.5832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:57:38.940233: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_20}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5468 - loss: 1.5761 - val_accuracy: 0.5675 - val_loss: 1.0998 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6514 - loss: 0.8480 - val_accuracy: 0.5652 - val_loss: 0.9411 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7175 - loss: 0.6951 - val_accuracy: 0.6087 - val_loss: 0.7807 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7403 - loss: 0.6326 - val_accuracy: 0.6584 - val_loss: 0.7022 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7439 - loss: 0.6007 - val_accuracy: 0.6104 - val_loss: 0.9077 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7546 - loss: 0.5727 - val_accuracy: 0.7041 - val_loss: 0.6254 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7595 - loss: 0.5646 - val_accuracy: 0.6126 - val_loss: 0.7978 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7702 - loss: 0.5554 - val_accuracy: 0.6798 - val_loss: 0.6733 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7630 - loss: 0.5481 - val_accuracy: 0.6273 - val_loss: 0.8161 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7802 - loss: 0.5295 - val_accuracy: 0.6364 - val_loss: 0.7575 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7889 - loss: 0.5066 - val_accuracy: 0.6606 - val_loss: 0.7123 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7929 - loss: 0.4928 - val_accuracy: 0.7149 - val_loss: 0.6229 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8092 - loss: 0.4709 - val_accuracy: 0.7194 - val_loss: 0.6205 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8157 - loss: 0.4623 - val_accuracy: 0.7211 - val_loss: 0.6166 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8176 - loss: 0.4566 - val_accuracy: 0.6996 - val_loss: 0.6618 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8235 - loss: 0.4489 - val_accuracy: 0.7132 - val_loss: 0.6202 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8245 - loss: 0.4424 - val_accuracy: 0.6866 - val_loss: 0.7088 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8252 - loss: 0.4377 - val_accuracy: 0.7205 - val_loss: 0.6016 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8431 - loss: 0.4243 - val_accuracy: 0.7397 - val_loss: 0.5965 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8315 - loss: 0.4268 - val_accuracy: 0.7324 - val_loss: 0.6141 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8345 - loss: 0.4163 - val_accuracy: 0.7301 - val_loss: 0.5997 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8401 - loss: 0.4154 - val_accuracy: 0.7307 - val_loss: 0.6033 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8449 - loss: 0.4127 - val_accuracy: 0.7064 - val_loss: 0.6633 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8499 - loss: 0.4013 - val_accuracy: 0.7324 - val_loss: 0.6043 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8561 - loss: 0.3793 - val_accuracy: 0.7357 - val_loss: 0.6227 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8607 - loss: 0.3693 - val_accuracy: 0.7369 - val_loss: 0.6121 - learning_rate: 2.5000e-04\n",
      "\u001b[1m18/56\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:58:28.495915: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_19}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Fold 1 Results:\n",
      "Accuracy: 0.7397\n",
      "Balanced Accuracy: 0.7375\n",
      "MCC: 0.4789\n",
      "Sensitivity: 0.7943\n",
      "Specificity: 0.6808\n",
      "Confusion Matrix:\n",
      "[[580 272]\n",
      " [189 730]]\n",
      "\n",
      "Fold 2/5\n",
      "Epoch 1/50\n",
      "\u001b[1m219/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5515 - loss: 1.6672"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:58:34.209706: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_20}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.5519 - loss: 1.6616 - val_accuracy: 0.5827 - val_loss: 1.0135 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6291 - loss: 0.9028 - val_accuracy: 0.5562 - val_loss: 0.9041 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6763 - loss: 0.7513 - val_accuracy: 0.5551 - val_loss: 0.9671 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7138 - loss: 0.6781 - val_accuracy: 0.5822 - val_loss: 0.7666 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7400 - loss: 0.6187 - val_accuracy: 0.6753 - val_loss: 0.6700 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7482 - loss: 0.5974 - val_accuracy: 0.6759 - val_loss: 0.6741 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7539 - loss: 0.5797 - val_accuracy: 0.6578 - val_loss: 0.6985 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7660 - loss: 0.5724 - val_accuracy: 0.6494 - val_loss: 0.7167 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7743 - loss: 0.5550 - val_accuracy: 0.7363 - val_loss: 0.5917 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7813 - loss: 0.5473 - val_accuracy: 0.7137 - val_loss: 0.6149 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7829 - loss: 0.5277 - val_accuracy: 0.7346 - val_loss: 0.5864 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7920 - loss: 0.5106 - val_accuracy: 0.7307 - val_loss: 0.5908 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7835 - loss: 0.5159 - val_accuracy: 0.6635 - val_loss: 0.6902 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8009 - loss: 0.5015 - val_accuracy: 0.6911 - val_loss: 0.6539 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7888 - loss: 0.5018 - val_accuracy: 0.6951 - val_loss: 0.6376 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8174 - loss: 0.4792 - val_accuracy: 0.7261 - val_loss: 0.6049 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8214 - loss: 0.4523 - val_accuracy: 0.7386 - val_loss: 0.5830 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8295 - loss: 0.4423 - val_accuracy: 0.7352 - val_loss: 0.5888 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8272 - loss: 0.4416 - val_accuracy: 0.6951 - val_loss: 0.6287 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8350 - loss: 0.4393 - val_accuracy: 0.6759 - val_loss: 0.7881 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8372 - loss: 0.4273 - val_accuracy: 0.7397 - val_loss: 0.5951 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8379 - loss: 0.4188 - val_accuracy: 0.7267 - val_loss: 0.6359 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8445 - loss: 0.4029 - val_accuracy: 0.7391 - val_loss: 0.6036 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8448 - loss: 0.3987 - val_accuracy: 0.7256 - val_loss: 0.6369 - learning_rate: 2.5000e-04\n",
      "\u001b[1m17/56\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:59:22.202652: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_19}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Fold 2 Results:\n",
      "Accuracy: 0.7386\n",
      "Balanced Accuracy: 0.7365\n",
      "MCC: 0.4765\n",
      "Sensitivity: 0.7911\n",
      "Specificity: 0.6819\n",
      "Confusion Matrix:\n",
      "[[581 271]\n",
      " [192 727]]\n",
      "\n",
      "Fold 3/5\n",
      "Epoch 1/50\n",
      "\u001b[1m  1/222\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:53\u001b[0m 2s/step - accuracy: 0.5938 - loss: 2.0924"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1740157166.137932  810749 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_7_1/dropout_14_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m221/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5500 - loss: 1.5485"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:59:28.169179: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_20}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5503 - loss: 1.5456 - val_accuracy: 0.5381 - val_loss: 1.0781 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6372 - loss: 0.8324 - val_accuracy: 0.5556 - val_loss: 0.8787 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6857 - loss: 0.7157 - val_accuracy: 0.5692 - val_loss: 0.8013 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7161 - loss: 0.6455 - val_accuracy: 0.6629 - val_loss: 0.7033 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7312 - loss: 0.6157 - val_accuracy: 0.6019 - val_loss: 0.8087 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7482 - loss: 0.5952 - val_accuracy: 0.7420 - val_loss: 0.5967 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7533 - loss: 0.5717 - val_accuracy: 0.6990 - val_loss: 0.6500 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7633 - loss: 0.5613 - val_accuracy: 0.7318 - val_loss: 0.5918 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7595 - loss: 0.5634 - val_accuracy: 0.7143 - val_loss: 0.6213 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7630 - loss: 0.5419 - val_accuracy: 0.6849 - val_loss: 0.6953 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7669 - loss: 0.5467 - val_accuracy: 0.6126 - val_loss: 0.8305 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7829 - loss: 0.5293 - val_accuracy: 0.6906 - val_loss: 0.6685 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7878 - loss: 0.5166 - val_accuracy: 0.6646 - val_loss: 0.7536 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7975 - loss: 0.4934 - val_accuracy: 0.6589 - val_loss: 0.7519 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8084 - loss: 0.4763 - val_accuracy: 0.7307 - val_loss: 0.6192 - learning_rate: 5.0000e-04\n",
      "\u001b[1m17/56\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:59:55.559990: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_19}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Fold 3 Results:\n",
      "Accuracy: 0.7318\n",
      "Balanced Accuracy: 0.7297\n",
      "MCC: 0.4631\n",
      "Sensitivity: 0.7876\n",
      "Specificity: 0.6717\n",
      "Confusion Matrix:\n",
      "[[573 280]\n",
      " [195 723]]\n",
      "\n",
      "Fold 4/5\n",
      "Epoch 1/50\n",
      "\u001b[1m217/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5620 - loss: 1.5217"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 17:00:01.303204: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_20}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.5628 - loss: 1.5131 - val_accuracy: 0.5475 - val_loss: 1.1805 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6609 - loss: 0.8187 - val_accuracy: 0.5390 - val_loss: 1.0684 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7004 - loss: 0.6990 - val_accuracy: 0.5746 - val_loss: 0.8299 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.6271 - val_accuracy: 0.5571 - val_loss: 1.0385 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7437 - loss: 0.5930 - val_accuracy: 0.5881 - val_loss: 0.9322 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7533 - loss: 0.5781 - val_accuracy: 0.7226 - val_loss: 0.5961 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7630 - loss: 0.5574 - val_accuracy: 0.6718 - val_loss: 0.6816 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7648 - loss: 0.5529 - val_accuracy: 0.6107 - val_loss: 0.8263 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7701 - loss: 0.5562 - val_accuracy: 0.7203 - val_loss: 0.6048 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7742 - loss: 0.5424 - val_accuracy: 0.7215 - val_loss: 0.5952 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7839 - loss: 0.5233 - val_accuracy: 0.7322 - val_loss: 0.5756 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7803 - loss: 0.5234 - val_accuracy: 0.7379 - val_loss: 0.5673 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7902 - loss: 0.5125 - val_accuracy: 0.7203 - val_loss: 0.6019 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7884 - loss: 0.5145 - val_accuracy: 0.7316 - val_loss: 0.5896 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7995 - loss: 0.5077 - val_accuracy: 0.7119 - val_loss: 0.6348 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8071 - loss: 0.4868 - val_accuracy: 0.6463 - val_loss: 0.8385 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8181 - loss: 0.4576 - val_accuracy: 0.6949 - val_loss: 0.6973 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8241 - loss: 0.4342 - val_accuracy: 0.7373 - val_loss: 0.6162 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8320 - loss: 0.4357 - val_accuracy: 0.7322 - val_loss: 0.6007 - learning_rate: 5.0000e-04\n",
      "\u001b[1m19/56\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 17:00:35.915182: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_19}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Fold 4 Results:\n",
      "Accuracy: 0.7379\n",
      "Balanced Accuracy: 0.7366\n",
      "MCC: 0.4746\n",
      "Sensitivity: 0.7702\n",
      "Specificity: 0.7031\n",
      "Confusion Matrix:\n",
      "[[599 253]\n",
      " [211 707]]\n",
      "\n",
      "Fold 5/5\n",
      "Epoch 1/50\n",
      "\u001b[1m  1/222\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:22\u001b[0m 2s/step - accuracy: 0.7188 - loss: 1.9855"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1740157239.741850  810749 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_9_1/dropout_18_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5783 - loss: 1.5231"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 17:00:41.726655: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_20}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.5783 - loss: 1.5218 - val_accuracy: 0.4814 - val_loss: 1.2315 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6462 - loss: 0.8023 - val_accuracy: 0.4814 - val_loss: 1.1004 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6794 - loss: 0.7035 - val_accuracy: 0.4814 - val_loss: 1.9049 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7206 - loss: 0.6319 - val_accuracy: 0.5870 - val_loss: 0.7683 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7440 - loss: 0.5974 - val_accuracy: 0.5921 - val_loss: 0.7371 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7431 - loss: 0.5795 - val_accuracy: 0.5401 - val_loss: 0.8593 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7513 - loss: 0.5648 - val_accuracy: 0.6209 - val_loss: 0.7236 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7646 - loss: 0.5610 - val_accuracy: 0.6621 - val_loss: 0.6661 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7697 - loss: 0.5477 - val_accuracy: 0.5972 - val_loss: 0.7799 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7786 - loss: 0.5375 - val_accuracy: 0.6294 - val_loss: 0.7322 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7821 - loss: 0.5273 - val_accuracy: 0.7011 - val_loss: 0.6231 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7835 - loss: 0.5218 - val_accuracy: 0.6836 - val_loss: 0.6327 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7719 - loss: 0.5302 - val_accuracy: 0.5938 - val_loss: 0.8187 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7924 - loss: 0.5117 - val_accuracy: 0.7153 - val_loss: 0.6170 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7930 - loss: 0.5144 - val_accuracy: 0.6395 - val_loss: 0.7441 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7898 - loss: 0.5101 - val_accuracy: 0.7469 - val_loss: 0.5861 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7989 - loss: 0.5046 - val_accuracy: 0.6571 - val_loss: 0.7306 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8074 - loss: 0.4943 - val_accuracy: 0.7350 - val_loss: 0.6165 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8204 - loss: 0.4768 - val_accuracy: 0.7328 - val_loss: 0.6159 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8150 - loss: 0.4849 - val_accuracy: 0.7158 - val_loss: 0.6618 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8220 - loss: 0.4586 - val_accuracy: 0.7249 - val_loss: 0.6376 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8389 - loss: 0.4318 - val_accuracy: 0.7181 - val_loss: 0.6407 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8399 - loss: 0.4187 - val_accuracy: 0.7175 - val_loss: 0.6541 - learning_rate: 5.0000e-04\n",
      "\u001b[1m19/56\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 17:01:26.619692: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_19}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Fold 5 Results:\n",
      "Accuracy: 0.7469\n",
      "Balanced Accuracy: 0.7460\n",
      "MCC: 0.4927\n",
      "Sensitivity: 0.7702\n",
      "Specificity: 0.7218\n",
      "Confusion Matrix:\n",
      "[[615 237]\n",
      " [211 707]]\n",
      "\n",
      "Average Cross-validation Results for GCN:\n",
      "accuracy: 0.7390 ± 0.0048\n",
      "balanced_accuracy: 0.7373 ± 0.0052\n",
      "mcc: 0.4772 ± 0.0095\n",
      "sensitivity: 0.7827 ± 0.0104\n",
      "specificity: 0.6919 ± 0.0182\n",
      "\n",
      "Final Test Set Results for GCN:\n",
      "Accuracy: 0.7157\n",
      "Balanced Accuracy: 0.7689\n",
      "MCC: 0.3205\n",
      "Sensitivity: 0.8333\n",
      "Specificity: 0.7044\n",
      "Confusion Matrix:\n",
      "[[1759  738]\n",
      " [  40  200]]\n",
      "\n",
      "Training GAT model\n",
      "\n",
      "Fold 1/5\n",
      "Epoch 1/50\n",
      "\u001b[1m221/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5523 - loss: 1.7714"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 17:01:34.186257: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_20}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.5525 - loss: 1.7690 - val_accuracy: 0.5528 - val_loss: 1.1530 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6447 - loss: 1.0546 - val_accuracy: 0.4845 - val_loss: 1.0086 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7015 - loss: 0.8207 - val_accuracy: 0.7075 - val_loss: 0.7389 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7210 - loss: 0.7047 - val_accuracy: 0.7233 - val_loss: 0.6575 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7438 - loss: 0.6379 - val_accuracy: 0.7205 - val_loss: 0.6333 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7468 - loss: 0.6060 - val_accuracy: 0.7160 - val_loss: 0.6294 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7589 - loss: 0.5751 - val_accuracy: 0.7047 - val_loss: 0.6792 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7655 - loss: 0.5614 - val_accuracy: 0.7239 - val_loss: 0.6075 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7768 - loss: 0.5455 - val_accuracy: 0.7199 - val_loss: 0.6020 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7878 - loss: 0.5256 - val_accuracy: 0.7199 - val_loss: 0.6097 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7824 - loss: 0.5209 - val_accuracy: 0.7007 - val_loss: 0.6257 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7846 - loss: 0.5083 - val_accuracy: 0.7120 - val_loss: 0.6741 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7979 - loss: 0.5024 - val_accuracy: 0.7188 - val_loss: 0.6105 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8158 - loss: 0.4809 - val_accuracy: 0.6584 - val_loss: 0.7514 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8184 - loss: 0.4600 - val_accuracy: 0.6940 - val_loss: 0.6828 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8247 - loss: 0.4525 - val_accuracy: 0.6652 - val_loss: 0.8016 - learning_rate: 5.0000e-04\n",
      "\u001b[1m 1/56\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 223ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 17:02:11.652249: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_19}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Fold 1 Results:\n",
      "Accuracy: 0.7199\n",
      "Balanced Accuracy: 0.7204\n",
      "MCC: 0.4405\n",
      "Sensitivity: 0.7084\n",
      "Specificity: 0.7324\n",
      "Confusion Matrix:\n",
      "[[624 228]\n",
      " [268 651]]\n",
      "\n",
      "Fold 2/5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1740157336.515389  810749 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_11_1/dropout_22_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m221/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5632 - loss: 1.8048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 17:02:19.175107: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_20}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.5633 - loss: 1.8024 - val_accuracy: 0.5974 - val_loss: 1.1530 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6378 - loss: 1.0750 - val_accuracy: 0.4845 - val_loss: 1.0606 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6683 - loss: 0.8696 - val_accuracy: 0.4969 - val_loss: 1.0123 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7043 - loss: 0.7427 - val_accuracy: 0.6522 - val_loss: 0.7436 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7354 - loss: 0.6627 - val_accuracy: 0.7002 - val_loss: 0.6747 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7512 - loss: 0.6102 - val_accuracy: 0.6183 - val_loss: 1.0298 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7629 - loss: 0.5896 - val_accuracy: 0.6906 - val_loss: 0.7135 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7790 - loss: 0.5569 - val_accuracy: 0.7013 - val_loss: 0.6447 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7845 - loss: 0.5312 - val_accuracy: 0.6725 - val_loss: 0.7506 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7908 - loss: 0.5242 - val_accuracy: 0.7137 - val_loss: 0.6666 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7872 - loss: 0.5209 - val_accuracy: 0.7233 - val_loss: 0.6298 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8002 - loss: 0.5071 - val_accuracy: 0.7098 - val_loss: 0.6773 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8058 - loss: 0.4953 - val_accuracy: 0.7109 - val_loss: 0.6587 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8121 - loss: 0.4915 - val_accuracy: 0.6979 - val_loss: 0.6821 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8208 - loss: 0.4925 - val_accuracy: 0.7024 - val_loss: 0.7060 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8344 - loss: 0.4549 - val_accuracy: 0.7194 - val_loss: 0.6656 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8424 - loss: 0.4296 - val_accuracy: 0.7335 - val_loss: 0.6647 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8447 - loss: 0.4177 - val_accuracy: 0.6838 - val_loss: 0.7582 - learning_rate: 5.0000e-04\n",
      "\u001b[1m 1/56\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 210ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 17:03:02.386195: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_19}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Fold 2 Results:\n",
      "Accuracy: 0.7233\n",
      "Balanced Accuracy: 0.7225\n",
      "MCC: 0.4455\n",
      "Sensitivity: 0.7443\n",
      "Specificity: 0.7007\n",
      "Confusion Matrix:\n",
      "[[597 255]\n",
      " [235 684]]\n",
      "\n",
      "Fold 3/5\n",
      "Epoch 1/50\n",
      "\u001b[1m220/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5611 - loss: 1.7220"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 17:03:10.155063: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_20}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.5614 - loss: 1.7184 - val_accuracy: 0.5184 - val_loss: 1.1522 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6419 - loss: 0.9813 - val_accuracy: 0.5184 - val_loss: 1.2512 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7000 - loss: 0.7735 - val_accuracy: 0.5438 - val_loss: 0.9501 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7267 - loss: 0.6618 - val_accuracy: 0.6962 - val_loss: 0.6727 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7464 - loss: 0.6037 - val_accuracy: 0.7199 - val_loss: 0.6182 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7413 - loss: 0.5710 - val_accuracy: 0.6674 - val_loss: 0.7267 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7556 - loss: 0.5620 - val_accuracy: 0.6894 - val_loss: 0.6784 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7677 - loss: 0.5364 - val_accuracy: 0.6906 - val_loss: 0.6624 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7655 - loss: 0.5296 - val_accuracy: 0.7408 - val_loss: 0.5779 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7700 - loss: 0.5229 - val_accuracy: 0.7521 - val_loss: 0.5798 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7788 - loss: 0.5113 - val_accuracy: 0.7205 - val_loss: 0.6016 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7868 - loss: 0.4943 - val_accuracy: 0.7301 - val_loss: 0.5897 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7931 - loss: 0.4958 - val_accuracy: 0.7273 - val_loss: 0.5978 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7932 - loss: 0.4763 - val_accuracy: 0.7267 - val_loss: 0.6103 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8208 - loss: 0.4442 - val_accuracy: 0.7363 - val_loss: 0.6179 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8131 - loss: 0.4459 - val_accuracy: 0.7103 - val_loss: 0.6546 - learning_rate: 5.0000e-04\n",
      "\u001b[1m 1/56\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 221ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 17:03:49.106166: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_19}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "Fold 3 Results:\n",
      "Accuracy: 0.7408\n",
      "Balanced Accuracy: 0.7393\n",
      "MCC: 0.4807\n",
      "Sensitivity: 0.7810\n",
      "Specificity: 0.6975\n",
      "Confusion Matrix:\n",
      "[[595 258]\n",
      " [201 717]]\n",
      "\n",
      "Fold 4/5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1740157433.972893  810749 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_13_1/dropout_26_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5487 - loss: 1.7683"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 17:03:56.706195: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_20}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.5488 - loss: 1.7671 - val_accuracy: 0.5215 - val_loss: 1.2334 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6391 - loss: 1.0553 - val_accuracy: 0.5209 - val_loss: 1.1037 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6689 - loss: 0.8341 - val_accuracy: 0.5418 - val_loss: 1.0156 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7023 - loss: 0.7330 - val_accuracy: 0.6554 - val_loss: 0.7504 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7242 - loss: 0.6490 - val_accuracy: 0.5938 - val_loss: 0.8623 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7451 - loss: 0.5937 - val_accuracy: 0.7311 - val_loss: 0.5982 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7604 - loss: 0.5583 - val_accuracy: 0.6576 - val_loss: 0.7485 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7612 - loss: 0.5548 - val_accuracy: 0.6757 - val_loss: 0.7267 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7744 - loss: 0.5342 - val_accuracy: 0.6644 - val_loss: 0.7658 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7766 - loss: 0.5237 - val_accuracy: 0.7175 - val_loss: 0.6325 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7917 - loss: 0.5039 - val_accuracy: 0.6927 - val_loss: 0.7085 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8036 - loss: 0.4791 - val_accuracy: 0.6847 - val_loss: 0.7075 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8199 - loss: 0.4597 - val_accuracy: 0.7085 - val_loss: 0.6901 - learning_rate: 5.0000e-04\n",
      "\u001b[1m 1/56\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 214ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 17:04:29.940392: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_19}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "Fold 4 Results:\n",
      "Accuracy: 0.7311\n",
      "Balanced Accuracy: 0.7276\n",
      "MCC: 0.4645\n",
      "Sensitivity: 0.8203\n",
      "Specificity: 0.6350\n",
      "Confusion Matrix:\n",
      "[[541 311]\n",
      " [165 753]]\n",
      "\n",
      "Fold 5/5\n",
      "Epoch 1/50\n",
      "\u001b[1m221/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5483 - loss: 1.8118"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 17:04:37.316419: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_20}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.5484 - loss: 1.8095 - val_accuracy: 0.4814 - val_loss: 1.1509 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6221 - loss: 1.0553 - val_accuracy: 0.4819 - val_loss: 1.0123 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6775 - loss: 0.8313 - val_accuracy: 0.4814 - val_loss: 1.0824 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7084 - loss: 0.7126 - val_accuracy: 0.4921 - val_loss: 1.0664 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7243 - loss: 0.6489 - val_accuracy: 0.5136 - val_loss: 0.9487 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7398 - loss: 0.6059 - val_accuracy: 0.6492 - val_loss: 0.6871 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7494 - loss: 0.5813 - val_accuracy: 0.6989 - val_loss: 0.6391 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7604 - loss: 0.5638 - val_accuracy: 0.6164 - val_loss: 0.7346 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7701 - loss: 0.5490 - val_accuracy: 0.6401 - val_loss: 0.6835 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7652 - loss: 0.5358 - val_accuracy: 0.6215 - val_loss: 0.7158 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7832 - loss: 0.5283 - val_accuracy: 0.6932 - val_loss: 0.6427 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7932 - loss: 0.4987 - val_accuracy: 0.7147 - val_loss: 0.6202 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8054 - loss: 0.4693 - val_accuracy: 0.7181 - val_loss: 0.6148 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8190 - loss: 0.4519 - val_accuracy: 0.6734 - val_loss: 0.7135 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8269 - loss: 0.4485 - val_accuracy: 0.7136 - val_loss: 0.6337 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8235 - loss: 0.4414 - val_accuracy: 0.7254 - val_loss: 0.6176 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8311 - loss: 0.4451 - val_accuracy: 0.7175 - val_loss: 0.6335 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8382 - loss: 0.4105 - val_accuracy: 0.7158 - val_loss: 0.6561 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8557 - loss: 0.3965 - val_accuracy: 0.7023 - val_loss: 0.7028 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8564 - loss: 0.3908 - val_accuracy: 0.7062 - val_loss: 0.6902 - learning_rate: 2.5000e-04\n",
      "\u001b[1m 1/56\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 184ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 17:05:25.966958: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_19}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "Fold 5 Results:\n",
      "Accuracy: 0.7181\n",
      "Balanced Accuracy: 0.7206\n",
      "MCC: 0.4441\n",
      "Sensitivity: 0.6525\n",
      "Specificity: 0.7887\n",
      "Confusion Matrix:\n",
      "[[672 180]\n",
      " [319 599]]\n",
      "\n",
      "Average Cross-validation Results for GAT:\n",
      "accuracy: 0.7266 ± 0.0084\n",
      "balanced_accuracy: 0.7261 ± 0.0071\n",
      "mcc: 0.4551 ± 0.0153\n",
      "sensitivity: 0.7413 ± 0.0580\n",
      "specificity: 0.7109 ± 0.0501\n",
      "\n",
      "Final Test Set Results for GAT:\n",
      "Accuracy: 0.7318\n",
      "Balanced Accuracy: 0.7382\n",
      "MCC: 0.2910\n",
      "Sensitivity: 0.7458\n",
      "Specificity: 0.7305\n",
      "Confusion Matrix:\n",
      "[[1824  673]\n",
      " [  61  179]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    # train_df = pd.read_csv(\"../data/processed_features_fixed_train_contactmap_copy.csv\")\n",
    "    # test_df = pd.read_csv(\"../data/processed_features_fixed_test_contactmap_copy.csv\")\n",
    "    train_df = pd.read_csv(\"../data/processed_features_fixed_train_contactmap.csv\")\n",
    "    test_df = pd.read_csv(\"../data/processed_features_fixed_test_contactmap.csv\")    \n",
    "    # Train with different thresholds\n",
    "    # For a single threshold\n",
    "    # To try a specific GNN type:\n",
    "    # results = train_with_cv(train_df, test_df, threshold=8.0, gnn_type='gcn')\n",
    "\n",
    "    # To try all GNN types:\n",
    "    results = train_with_cv(train_df, test_df, threshold=8.0)\n",
    "\n",
    "    # Or try multiple thresholds\n",
    "    # thresholds = [6.0, 8.0, 10.0, 12.0]\n",
    "    # for threshold in thresholds:\n",
    "    #     print(f\"\\nEvaluating threshold {threshold}Å\")\n",
    "    #     model, history, cv_metrics = train_with_cv(train_df, test_df, threshold=threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune-dephos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
