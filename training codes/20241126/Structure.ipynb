{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "tf.keras.utils.set_random_seed(SEED)  # This sets all random seeds in keras\n",
    "tf.config.experimental.enable_op_determinism()  # For complete reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_structure_data(df):\n",
    "   \"\"\"Prepare and normalize structural features\"\"\"\n",
    "   # Extract SASA\n",
    "   sasa = df['sasa'].values.reshape(-1, 1)\n",
    "   \n",
    "   # Convert string arrays to numerical arrays for angles\n",
    "   phi_small = np.array([eval(x) for x in df['phi_small']])\n",
    "   psi_small = np.array([eval(x) for x in df['psi_small']])\n",
    "   \n",
    "   # Convert secondary structure to one-hot encoding\n",
    "   ss = np.column_stack((df['E'], df['H'], df['L']))\n",
    "   \n",
    "   # Normalize SASA and angles\n",
    "   scaler_sasa = StandardScaler()\n",
    "   sasa_normalized = scaler_sasa.fit_transform(sasa)\n",
    "   \n",
    "   scaler_phi = StandardScaler()\n",
    "   phi_normalized = scaler_phi.fit_transform(phi_small)\n",
    "   \n",
    "   scaler_psi = StandardScaler()\n",
    "   psi_normalized = scaler_psi.fit_transform(psi_small)\n",
    "   \n",
    "   # Combine all features\n",
    "   features = np.concatenate([\n",
    "       sasa_normalized,\n",
    "       phi_normalized,\n",
    "       psi_normalized,\n",
    "       ss\n",
    "   ], axis=1)\n",
    "   \n",
    "   return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_structure_model():\n",
    "   \"\"\"Create model for structural features\"\"\"\n",
    "   model = tf.keras.Sequential([\n",
    "       tf.keras.layers.Input(shape=(10,)),  # 1 SASA + 3 phi + 3 psi + 3 SS\n",
    "       tf.keras.layers.Dense(32, activation='relu'),\n",
    "       tf.keras.layers.Dropout(0.2),\n",
    "       tf.keras.layers.Dense(16, activation='relu'),\n",
    "       tf.keras.layers.Dropout(0.2),\n",
    "       tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "   ])\n",
    "   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_enhanced_structure_model():\n",
    "    \"\"\"Create enhanced model for structural features\"\"\"\n",
    "    # Input layer\n",
    "    inputs = tf.keras.layers.Input(shape=(10,))\n",
    "    \n",
    "    # Normalize inputs\n",
    "    x = tf.keras.layers.BatchNormalization()(inputs)\n",
    "    \n",
    "    # First block with residual connection\n",
    "    main = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    main = tf.keras.layers.BatchNormalization()(main)\n",
    "    main = tf.keras.layers.Dropout(0.3)(main)\n",
    "    main = tf.keras.layers.Dense(64)(main)\n",
    "    skip = tf.keras.layers.Dense(64)(x)\n",
    "    x = tf.keras.layers.Add()([main, skip])\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    # Second block\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "    # Separate branches for different feature types\n",
    "    # SASA branch\n",
    "    sasa = tf.keras.layers.Lambda(lambda x: x[:, 0:1])(inputs)\n",
    "    sasa = tf.keras.layers.Dense(8, activation='relu')(sasa)\n",
    "    \n",
    "    # Angles branch (phi/psi)\n",
    "    angles = tf.keras.layers.Lambda(lambda x: x[:, 1:7])(inputs)\n",
    "    angles = tf.keras.layers.Dense(16, activation='relu')(angles)\n",
    "    \n",
    "    # Secondary structure branch\n",
    "    ss = tf.keras.layers.Lambda(lambda x: x[:, 7:10])(inputs)\n",
    "    ss = tf.keras.layers.Dense(8, activation='relu')(ss)\n",
    "    \n",
    "    # Combine all features\n",
    "    combined = tf.keras.layers.Concatenate()([x, sasa, angles, ss])\n",
    "    \n",
    "    # Final layers\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(combined)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate():\n",
    "   # Load data\n",
    "   print(\"Loading data...\")\n",
    "   train_df = pd.read_csv(\"../new/processed_data_train.csv\")\n",
    "   test_df = pd.read_csv(\"../new/processed_data_test.csv\")\n",
    "   \n",
    "   # Shuffle both training and test data\n",
    "   print(\"Shuffling data...\")\n",
    "   train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "   test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "   \n",
    "   # Print class distribution\n",
    "   print(\"\\nTraining set distribution:\")\n",
    "   print(train_df['label'].value_counts())\n",
    "   print(\"\\nTest set distribution:\")\n",
    "   print(test_df['label'].value_counts())\n",
    "   \n",
    "   # Prepare structure data\n",
    "   print(\"\\nPreparing structure data...\")\n",
    "   X_train = prepare_structure_data(train_df)\n",
    "   X_test = prepare_structure_data(test_df)\n",
    "   \n",
    "   y_train = train_df['label'].values\n",
    "   y_test = test_df['label'].values\n",
    "   \n",
    "   print(f\"\\nTraining data shape: {X_train.shape}\")\n",
    "   print(f\"Test data shape: {X_test.shape}\")\n",
    "   \n",
    "   # Calculate class weights\n",
    "   total_samples = len(y_train)\n",
    "   pos_samples = np.sum(y_train == 1)\n",
    "   neg_samples = np.sum(y_train == 0)\n",
    "   \n",
    "   class_weights = {\n",
    "       0: total_samples / (2 * neg_samples),\n",
    "       1: total_samples / (2 * pos_samples)\n",
    "   }\n",
    "   \n",
    "   print(\"\\nClass weights:\", class_weights)\n",
    "   \n",
    "   # Initialize cross-validation\n",
    "   kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "   \n",
    "   # Initialize metrics storage\n",
    "   metrics = {'acc': [], 'balanced_acc': [], 'mcc': [], 'sn': [], 'sp': []}\n",
    "   test_predictions = []\n",
    "   \n",
    "   # Cross-validation loop\n",
    "   for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train), 1):\n",
    "       print(f\"\\nFold {fold}/5\")\n",
    "       \n",
    "       # Create callbacks\n",
    "       early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "           monitor='val_loss',  # Changed to monitor loss instead of accuracy\n",
    "           patience=5,\n",
    "           restore_best_weights=True\n",
    "       )\n",
    "       \n",
    "       # Create and compile model\n",
    "       model = create_structure_model()\n",
    "       model.compile(\n",
    "           optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "           loss='binary_crossentropy',\n",
    "           metrics=['accuracy']\n",
    "       )\n",
    "       \n",
    "       # Train model\n",
    "       print(\"Training model...\")\n",
    "       history = model.fit(\n",
    "           X_train[train_idx], y_train[train_idx],\n",
    "           batch_size=32,\n",
    "           epochs=50,\n",
    "           validation_data=(X_train[val_idx], y_train[val_idx]),\n",
    "           callbacks=[early_stopping],\n",
    "           class_weight=class_weights,\n",
    "           verbose=1\n",
    "       )\n",
    "       \n",
    "       # Plot training history\n",
    "       plt.figure(figsize=(10, 6))\n",
    "       plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "       plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "       plt.title(f'Model Accuracy - Fold {fold}')\n",
    "       plt.xlabel('Epoch')\n",
    "       plt.ylabel('Accuracy')\n",
    "       plt.legend()\n",
    "       plt.show()\n",
    "    #    plt.savefig(f'structure_accuracy_fold_{fold}.png')\n",
    "    #    plt.close()\n",
    "       \n",
    "       # Evaluate on validation set\n",
    "       y_pred = model.predict(X_train[val_idx])\n",
    "       y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "       \n",
    "       # Calculate metrics\n",
    "       cm = confusion_matrix(y_train[val_idx], y_pred_binary)\n",
    "       metrics['acc'].append(accuracy_score(y_train[val_idx], y_pred_binary))\n",
    "       metrics['balanced_acc'].append(balanced_accuracy_score(y_train[val_idx], y_pred_binary))\n",
    "       metrics['mcc'].append(matthews_corrcoef(y_train[val_idx], y_pred_binary))\n",
    "       metrics['sn'].append(cm[1][1]/(cm[1][1]+cm[1][0]))  # Sensitivity\n",
    "       metrics['sp'].append(cm[0][0]/(cm[0][0]+cm[0][1]))  # Specificity\n",
    "       \n",
    "       # Predict on test set\n",
    "       test_pred = model.predict(X_test)\n",
    "       test_predictions.append(test_pred)\n",
    "       \n",
    "       print(f\"\\nFold {fold} Results:\")\n",
    "       print(f\"Accuracy: {metrics['acc'][-1]:.4f}\")\n",
    "       print(f\"Balanced Accuracy: {metrics['balanced_acc'][-1]:.4f}\")\n",
    "       print(f\"MCC: {metrics['mcc'][-1]:.4f}\")\n",
    "       print(f\"Sensitivity: {metrics['sn'][-1]:.4f}\")\n",
    "       print(f\"Specificity: {metrics['sp'][-1]:.4f}\")\n",
    "   \n",
    "   # Print average cross-validation results\n",
    "   print(\"\\nAverage Cross-validation Results:\")\n",
    "   for metric in metrics:\n",
    "       print(f\"{metric.upper()}: {np.mean(metrics[metric]):.4f} ± {np.std(metrics[metric]):.4f}\")\n",
    "   \n",
    "   # Ensemble predictions on test set\n",
    "   test_pred_avg = np.mean(test_predictions, axis=0)\n",
    "   test_pred_binary = (test_pred_avg > 0.5).astype(int)\n",
    "   \n",
    "   # Calculate final test metrics\n",
    "   cm_test = confusion_matrix(y_test, test_pred_binary)\n",
    "   test_balanced_acc = balanced_accuracy_score(y_test, test_pred_binary)\n",
    "   \n",
    "   print(\"\\nFinal Test Set Results:\")\n",
    "   print(f\"Accuracy: {accuracy_score(y_test, test_pred_binary):.4f}\")\n",
    "   print(f\"Balanced Accuracy: {test_balanced_acc:.4f}\")\n",
    "   print(f\"MCC: {matthews_corrcoef(y_test, test_pred_binary):.4f}\")\n",
    "   print(f\"Sensitivity: {cm_test[1][1]/(cm_test[1][1]+cm_test[1][0]):.4f}\")\n",
    "   print(f\"Specificity: {cm_test[0][0]/(cm_test[0][0]+cm_test[0][1]):.4f}\")\n",
    "   print(\"Confusion Matrix:\")\n",
    "   print(cm_test)\n",
    "   \n",
    "   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Shuffling data...\n",
      "\n",
      "Training set distribution:\n",
      "label\n",
      "1    4591\n",
      "0    4259\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set distribution:\n",
      "label\n",
      "0    2497\n",
      "1     240\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Preparing structure data...\n",
      "\n",
      "Training data shape: (8850, 10)\n",
      "Test data shape: (2737, 10)\n",
      "\n",
      "Class weights: {0: 1.0389762855130311, 1: 0.9638423001524722}\n",
      "\n",
      "Fold 1/5\n",
      "Training model...\n",
      "Epoch 1/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5072 - loss: 0.7055 - val_accuracy: 0.5249 - val_loss: 0.6920\n",
      "Epoch 2/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5205 - loss: 0.6935 - val_accuracy: 0.5294 - val_loss: 0.6932\n",
      "Epoch 3/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5272 - loss: 0.6900 - val_accuracy: 0.5345 - val_loss: 0.6923\n",
      "Epoch 4/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5381 - loss: 0.6889 - val_accuracy: 0.5367 - val_loss: 0.6900\n",
      "Epoch 5/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5373 - loss: 0.6878 - val_accuracy: 0.5429 - val_loss: 0.6906\n",
      "Epoch 6/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5325 - loss: 0.6889 - val_accuracy: 0.5503 - val_loss: 0.6896\n",
      "Epoch 7/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5465 - loss: 0.6866 - val_accuracy: 0.5599 - val_loss: 0.6874\n",
      "Epoch 8/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5469 - loss: 0.6862 - val_accuracy: 0.5542 - val_loss: 0.6888\n",
      "Epoch 9/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5361 - loss: 0.6862 - val_accuracy: 0.5599 - val_loss: 0.6885\n",
      "Epoch 10/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5464 - loss: 0.6852 - val_accuracy: 0.5610 - val_loss: 0.6875\n",
      "Epoch 11/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5470 - loss: 0.6843 - val_accuracy: 0.5588 - val_loss: 0.6871\n",
      "Epoch 12/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5488 - loss: 0.6844 - val_accuracy: 0.5638 - val_loss: 0.6884\n",
      "Epoch 13/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5417 - loss: 0.6852 - val_accuracy: 0.5695 - val_loss: 0.6875\n",
      "Epoch 14/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5565 - loss: 0.6816 - val_accuracy: 0.5627 - val_loss: 0.6871\n",
      "Epoch 15/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5553 - loss: 0.6839 - val_accuracy: 0.5610 - val_loss: 0.6876\n",
      "Epoch 16/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5525 - loss: 0.6825 - val_accuracy: 0.5638 - val_loss: 0.6884\n",
      "Epoch 17/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5535 - loss: 0.6831 - val_accuracy: 0.5610 - val_loss: 0.6876\n",
      "Epoch 18/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5568 - loss: 0.6823 - val_accuracy: 0.5571 - val_loss: 0.6878\n",
      "Epoch 19/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5500 - loss: 0.6849 - val_accuracy: 0.5582 - val_loss: 0.6870\n",
      "Epoch 20/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5601 - loss: 0.6798 - val_accuracy: 0.5559 - val_loss: 0.6885\n",
      "Epoch 21/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5592 - loss: 0.6810 - val_accuracy: 0.5644 - val_loss: 0.6870\n",
      "Epoch 22/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5404 - loss: 0.6846 - val_accuracy: 0.5576 - val_loss: 0.6900\n",
      "Epoch 23/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5627 - loss: 0.6777 - val_accuracy: 0.5616 - val_loss: 0.6870\n",
      "Epoch 24/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5555 - loss: 0.6814 - val_accuracy: 0.5667 - val_loss: 0.6863\n",
      "Epoch 25/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5642 - loss: 0.6780 - val_accuracy: 0.5593 - val_loss: 0.6874\n",
      "Epoch 26/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5457 - loss: 0.6817 - val_accuracy: 0.5621 - val_loss: 0.6881\n",
      "Epoch 27/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5561 - loss: 0.6831 - val_accuracy: 0.5588 - val_loss: 0.6891\n",
      "Epoch 28/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5470 - loss: 0.6808 - val_accuracy: 0.5627 - val_loss: 0.6872\n",
      "Epoch 29/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5488 - loss: 0.6795 - val_accuracy: 0.5588 - val_loss: 0.6864\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\n",
      "Fold 1 Results:\n",
      "Accuracy: 0.5667\n",
      "Balanced Accuracy: 0.5500\n",
      "MCC: 0.1078\n",
      "Sensitivity: 0.7365\n",
      "Specificity: 0.3635\n",
      "\n",
      "Fold 2/5\n",
      "Training model...\n",
      "Epoch 1/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.5049 - loss: 0.7218 - val_accuracy: 0.5215 - val_loss: 0.6934\n",
      "Epoch 2/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5041 - loss: 0.6974 - val_accuracy: 0.5282 - val_loss: 0.6912\n",
      "Epoch 3/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5175 - loss: 0.6955 - val_accuracy: 0.5350 - val_loss: 0.6906\n",
      "Epoch 4/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5355 - loss: 0.6914 - val_accuracy: 0.5537 - val_loss: 0.6889\n",
      "Epoch 5/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5411 - loss: 0.6892 - val_accuracy: 0.5446 - val_loss: 0.6891\n",
      "Epoch 6/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5410 - loss: 0.6874 - val_accuracy: 0.5480 - val_loss: 0.6873\n",
      "Epoch 7/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5282 - loss: 0.6890 - val_accuracy: 0.5599 - val_loss: 0.6871\n",
      "Epoch 8/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5452 - loss: 0.6863 - val_accuracy: 0.5610 - val_loss: 0.6862\n",
      "Epoch 9/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5540 - loss: 0.6855 - val_accuracy: 0.5616 - val_loss: 0.6851\n",
      "Epoch 10/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5366 - loss: 0.6872 - val_accuracy: 0.5650 - val_loss: 0.6843\n",
      "Epoch 11/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5524 - loss: 0.6858 - val_accuracy: 0.5650 - val_loss: 0.6835\n",
      "Epoch 12/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5476 - loss: 0.6846 - val_accuracy: 0.5706 - val_loss: 0.6834\n",
      "Epoch 13/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5580 - loss: 0.6842 - val_accuracy: 0.5763 - val_loss: 0.6824\n",
      "Epoch 14/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5479 - loss: 0.6847 - val_accuracy: 0.5672 - val_loss: 0.6826\n",
      "Epoch 15/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5530 - loss: 0.6850 - val_accuracy: 0.5746 - val_loss: 0.6820\n",
      "Epoch 16/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5572 - loss: 0.6835 - val_accuracy: 0.5695 - val_loss: 0.6817\n",
      "Epoch 17/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5603 - loss: 0.6820 - val_accuracy: 0.5729 - val_loss: 0.6819\n",
      "Epoch 18/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5599 - loss: 0.6810 - val_accuracy: 0.5650 - val_loss: 0.6825\n",
      "Epoch 19/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5547 - loss: 0.6837 - val_accuracy: 0.5746 - val_loss: 0.6814\n",
      "Epoch 20/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5583 - loss: 0.6844 - val_accuracy: 0.5757 - val_loss: 0.6813\n",
      "Epoch 21/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5583 - loss: 0.6795 - val_accuracy: 0.5831 - val_loss: 0.6806\n",
      "Epoch 22/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5567 - loss: 0.6815 - val_accuracy: 0.5746 - val_loss: 0.6809\n",
      "Epoch 23/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5551 - loss: 0.6828 - val_accuracy: 0.5791 - val_loss: 0.6811\n",
      "Epoch 24/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5670 - loss: 0.6797 - val_accuracy: 0.5785 - val_loss: 0.6804\n",
      "Epoch 25/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5627 - loss: 0.6780 - val_accuracy: 0.5785 - val_loss: 0.6812\n",
      "Epoch 26/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5480 - loss: 0.6813 - val_accuracy: 0.5768 - val_loss: 0.6813\n",
      "Epoch 27/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5622 - loss: 0.6805 - val_accuracy: 0.5757 - val_loss: 0.6810\n",
      "Epoch 28/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5549 - loss: 0.6809 - val_accuracy: 0.5729 - val_loss: 0.6810\n",
      "Epoch 29/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5523 - loss: 0.6809 - val_accuracy: 0.5785 - val_loss: 0.6813\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\n",
      "Fold 2 Results:\n",
      "Accuracy: 0.5785\n",
      "Balanced Accuracy: 0.5666\n",
      "MCC: 0.1445\n",
      "Sensitivity: 0.7585\n",
      "Specificity: 0.3747\n",
      "\n",
      "Fold 3/5\n",
      "Training model...\n",
      "Epoch 1/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.4912 - loss: 0.7100 - val_accuracy: 0.5237 - val_loss: 0.6905\n",
      "Epoch 2/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5253 - loss: 0.6921 - val_accuracy: 0.5328 - val_loss: 0.6887\n",
      "Epoch 3/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5339 - loss: 0.6909 - val_accuracy: 0.5237 - val_loss: 0.6879\n",
      "Epoch 4/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5403 - loss: 0.6883 - val_accuracy: 0.5345 - val_loss: 0.6877\n",
      "Epoch 5/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5512 - loss: 0.6867 - val_accuracy: 0.5401 - val_loss: 0.6869\n",
      "Epoch 6/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5521 - loss: 0.6842 - val_accuracy: 0.5401 - val_loss: 0.6858\n",
      "Epoch 7/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5581 - loss: 0.6827 - val_accuracy: 0.5362 - val_loss: 0.6856\n",
      "Epoch 8/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5561 - loss: 0.6827 - val_accuracy: 0.5373 - val_loss: 0.6850\n",
      "Epoch 9/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5655 - loss: 0.6826 - val_accuracy: 0.5379 - val_loss: 0.6846\n",
      "Epoch 10/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5610 - loss: 0.6807 - val_accuracy: 0.5441 - val_loss: 0.6844\n",
      "Epoch 11/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5708 - loss: 0.6789 - val_accuracy: 0.5373 - val_loss: 0.6842\n",
      "Epoch 12/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5658 - loss: 0.6778 - val_accuracy: 0.5367 - val_loss: 0.6833\n",
      "Epoch 13/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5655 - loss: 0.6811 - val_accuracy: 0.5407 - val_loss: 0.6833\n",
      "Epoch 14/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5641 - loss: 0.6796 - val_accuracy: 0.5395 - val_loss: 0.6835\n",
      "Epoch 15/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5621 - loss: 0.6792 - val_accuracy: 0.5429 - val_loss: 0.6834\n",
      "Epoch 16/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5650 - loss: 0.6802 - val_accuracy: 0.5469 - val_loss: 0.6833\n",
      "Epoch 17/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5581 - loss: 0.6785 - val_accuracy: 0.5412 - val_loss: 0.6834\n",
      "Epoch 18/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5675 - loss: 0.6761 - val_accuracy: 0.5446 - val_loss: 0.6827\n",
      "Epoch 19/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5585 - loss: 0.6758 - val_accuracy: 0.5452 - val_loss: 0.6825\n",
      "Epoch 20/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5626 - loss: 0.6780 - val_accuracy: 0.5435 - val_loss: 0.6825\n",
      "Epoch 21/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5780 - loss: 0.6783 - val_accuracy: 0.5531 - val_loss: 0.6814\n",
      "Epoch 22/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5731 - loss: 0.6784 - val_accuracy: 0.5441 - val_loss: 0.6820\n",
      "Epoch 23/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5606 - loss: 0.6765 - val_accuracy: 0.5446 - val_loss: 0.6817\n",
      "Epoch 24/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5736 - loss: 0.6746 - val_accuracy: 0.5469 - val_loss: 0.6822\n",
      "Epoch 25/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5731 - loss: 0.6746 - val_accuracy: 0.5446 - val_loss: 0.6827\n",
      "Epoch 26/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5651 - loss: 0.6765 - val_accuracy: 0.5469 - val_loss: 0.6828\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\n",
      "Fold 3 Results:\n",
      "Accuracy: 0.5531\n",
      "Balanced Accuracy: 0.5510\n",
      "MCC: 0.1152\n",
      "Sensitivity: 0.7828\n",
      "Specificity: 0.3193\n",
      "\n",
      "Fold 4/5\n",
      "Training model...\n",
      "Epoch 1/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5149 - loss: 0.7053 - val_accuracy: 0.5379 - val_loss: 0.6878\n",
      "Epoch 2/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5076 - loss: 0.6949 - val_accuracy: 0.5458 - val_loss: 0.6883\n",
      "Epoch 3/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5093 - loss: 0.6939 - val_accuracy: 0.5565 - val_loss: 0.6867\n",
      "Epoch 4/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5302 - loss: 0.6917 - val_accuracy: 0.5492 - val_loss: 0.6873\n",
      "Epoch 5/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5331 - loss: 0.6898 - val_accuracy: 0.5542 - val_loss: 0.6864\n",
      "Epoch 6/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5388 - loss: 0.6873 - val_accuracy: 0.5492 - val_loss: 0.6852\n",
      "Epoch 7/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5381 - loss: 0.6891 - val_accuracy: 0.5497 - val_loss: 0.6853\n",
      "Epoch 8/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5477 - loss: 0.6860 - val_accuracy: 0.5475 - val_loss: 0.6851\n",
      "Epoch 9/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5447 - loss: 0.6866 - val_accuracy: 0.5452 - val_loss: 0.6848\n",
      "Epoch 10/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5431 - loss: 0.6863 - val_accuracy: 0.5435 - val_loss: 0.6839\n",
      "Epoch 11/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5397 - loss: 0.6865 - val_accuracy: 0.5486 - val_loss: 0.6840\n",
      "Epoch 12/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5340 - loss: 0.6868 - val_accuracy: 0.5429 - val_loss: 0.6839\n",
      "Epoch 13/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5465 - loss: 0.6842 - val_accuracy: 0.5475 - val_loss: 0.6837\n",
      "Epoch 14/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5460 - loss: 0.6839 - val_accuracy: 0.5475 - val_loss: 0.6844\n",
      "Epoch 15/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5636 - loss: 0.6845 - val_accuracy: 0.5492 - val_loss: 0.6836\n",
      "Epoch 16/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5478 - loss: 0.6837 - val_accuracy: 0.5412 - val_loss: 0.6853\n",
      "Epoch 17/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5539 - loss: 0.6834 - val_accuracy: 0.5531 - val_loss: 0.6843\n",
      "Epoch 18/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5442 - loss: 0.6859 - val_accuracy: 0.5480 - val_loss: 0.6836\n",
      "Epoch 19/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5533 - loss: 0.6848 - val_accuracy: 0.5446 - val_loss: 0.6833\n",
      "Epoch 20/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5598 - loss: 0.6822 - val_accuracy: 0.5497 - val_loss: 0.6824\n",
      "Epoch 21/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5614 - loss: 0.6816 - val_accuracy: 0.5503 - val_loss: 0.6822\n",
      "Epoch 22/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5498 - loss: 0.6812 - val_accuracy: 0.5441 - val_loss: 0.6844\n",
      "Epoch 23/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5531 - loss: 0.6811 - val_accuracy: 0.5548 - val_loss: 0.6834\n",
      "Epoch 24/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5635 - loss: 0.6816 - val_accuracy: 0.5463 - val_loss: 0.6820\n",
      "Epoch 25/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5586 - loss: 0.6822 - val_accuracy: 0.5525 - val_loss: 0.6833\n",
      "Epoch 26/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5666 - loss: 0.6824 - val_accuracy: 0.5520 - val_loss: 0.6823\n",
      "Epoch 27/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5646 - loss: 0.6820 - val_accuracy: 0.5486 - val_loss: 0.6827\n",
      "Epoch 28/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5587 - loss: 0.6795 - val_accuracy: 0.5458 - val_loss: 0.6831\n",
      "Epoch 29/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5706 - loss: 0.6795 - val_accuracy: 0.5469 - val_loss: 0.6824\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\n",
      "Fold 4 Results:\n",
      "Accuracy: 0.5463\n",
      "Balanced Accuracy: 0.5476\n",
      "MCC: 0.1024\n",
      "Sensitivity: 0.7327\n",
      "Specificity: 0.3625\n",
      "\n",
      "Fold 5/5\n",
      "Training model...\n",
      "Epoch 1/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4826 - loss: 0.7226 - val_accuracy: 0.5294 - val_loss: 0.6925\n",
      "Epoch 2/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5189 - loss: 0.6969 - val_accuracy: 0.5395 - val_loss: 0.6888\n",
      "Epoch 3/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5355 - loss: 0.6912 - val_accuracy: 0.5339 - val_loss: 0.6877\n",
      "Epoch 4/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5297 - loss: 0.6927 - val_accuracy: 0.5322 - val_loss: 0.6877\n",
      "Epoch 5/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5262 - loss: 0.6900 - val_accuracy: 0.5328 - val_loss: 0.6872\n",
      "Epoch 6/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5441 - loss: 0.6868 - val_accuracy: 0.5350 - val_loss: 0.6874\n",
      "Epoch 7/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5464 - loss: 0.6868 - val_accuracy: 0.5418 - val_loss: 0.6863\n",
      "Epoch 8/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5500 - loss: 0.6877 - val_accuracy: 0.5435 - val_loss: 0.6859\n",
      "Epoch 9/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5395 - loss: 0.6864 - val_accuracy: 0.5446 - val_loss: 0.6852\n",
      "Epoch 10/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5556 - loss: 0.6844 - val_accuracy: 0.5350 - val_loss: 0.6852\n",
      "Epoch 11/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5439 - loss: 0.6844 - val_accuracy: 0.5452 - val_loss: 0.6854\n",
      "Epoch 12/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5570 - loss: 0.6834 - val_accuracy: 0.5480 - val_loss: 0.6852\n",
      "Epoch 13/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5531 - loss: 0.6855 - val_accuracy: 0.5492 - val_loss: 0.6847\n",
      "Epoch 14/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5589 - loss: 0.6825 - val_accuracy: 0.5446 - val_loss: 0.6840\n",
      "Epoch 15/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5602 - loss: 0.6819 - val_accuracy: 0.5486 - val_loss: 0.6848\n",
      "Epoch 16/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5593 - loss: 0.6818 - val_accuracy: 0.5446 - val_loss: 0.6846\n",
      "Epoch 17/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5471 - loss: 0.6852 - val_accuracy: 0.5492 - val_loss: 0.6839\n",
      "Epoch 18/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5541 - loss: 0.6831 - val_accuracy: 0.5480 - val_loss: 0.6839\n",
      "Epoch 19/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5582 - loss: 0.6776 - val_accuracy: 0.5469 - val_loss: 0.6837\n",
      "Epoch 20/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5568 - loss: 0.6826 - val_accuracy: 0.5492 - val_loss: 0.6837\n",
      "Epoch 21/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5579 - loss: 0.6800 - val_accuracy: 0.5486 - val_loss: 0.6840\n",
      "Epoch 22/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5623 - loss: 0.6796 - val_accuracy: 0.5565 - val_loss: 0.6843\n",
      "Epoch 23/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5522 - loss: 0.6809 - val_accuracy: 0.5571 - val_loss: 0.6839\n",
      "Epoch 24/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5546 - loss: 0.6833 - val_accuracy: 0.5531 - val_loss: 0.6833\n",
      "Epoch 25/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5585 - loss: 0.6836 - val_accuracy: 0.5520 - val_loss: 0.6839\n",
      "Epoch 26/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5674 - loss: 0.6807 - val_accuracy: 0.5486 - val_loss: 0.6844\n",
      "Epoch 27/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5583 - loss: 0.6788 - val_accuracy: 0.5531 - val_loss: 0.6842\n",
      "Epoch 28/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5579 - loss: 0.6793 - val_accuracy: 0.5525 - val_loss: 0.6845\n",
      "Epoch 29/50\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5697 - loss: 0.6799 - val_accuracy: 0.5508 - val_loss: 0.6849\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\n",
      "Fold 5 Results:\n",
      "Accuracy: 0.5531\n",
      "Balanced Accuracy: 0.5476\n",
      "MCC: 0.1007\n",
      "Sensitivity: 0.7115\n",
      "Specificity: 0.3836\n",
      "\n",
      "Average Cross-validation Results:\n",
      "ACC: 0.5595 ± 0.0116\n",
      "BALANCED_ACC: 0.5526 ± 0.0072\n",
      "MCC: 0.1141 ± 0.0160\n",
      "SN: 0.7444 ± 0.0243\n",
      "SP: 0.3607 ± 0.0221\n",
      "\n",
      "Final Test Set Results:\n",
      "Accuracy: 0.3778\n",
      "Balanced Accuracy: 0.5422\n",
      "MCC: 0.0506\n",
      "Sensitivity: 0.7417\n",
      "Specificity: 0.3428\n",
      "Confusion Matrix:\n",
      "[[ 856 1641]\n",
      " [  62  178]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = train_and_evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
